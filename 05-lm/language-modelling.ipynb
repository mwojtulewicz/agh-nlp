{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdxOVe0GHwRv"
      },
      "source": [
        "# Language modelling\n",
        "Mateusz Wojtulewicz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ef7UWLtmH19W"
      },
      "source": [
        "## 1. Read the documentation of [Language modelling in the Transformers](https://huggingface.co/docs/transformers/task_summary#language-modeling).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZ7t37HVKEyg",
        "outputId": "21eedba7-2348-48cf-a131-d320bbf7c2db",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Done.\n"
          ]
        }
      ],
      "source": [
        "from IPython.display import clear_output \n",
        "\n",
        "!pip install transformers\n",
        "!pip install sacremoses\n",
        "\n",
        "clear_output()\n",
        "print(\"Done.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "_sxML4t-u6tO",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "from transformers import (\n",
        "    AutoTokenizer, \n",
        "    AutoModelForMaskedLM, \n",
        "    AutoModelWithLMHead, \n",
        "    BertTokenizer, \n",
        "    BertForMaskedLM, \n",
        "    AutoModel,\n",
        "    pipeline\n",
        ")\n",
        "\n",
        "from pprint import pprint"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJMyHifsuYZf"
      },
      "source": [
        "## 2. Download three [Polish models](https://huggingface.co/models?filter=pl) from the Huggingface repository.\n",
        "\n",
        "I'm using a Polish BERT model, a Polish GPT-2 model and a multilingual XLM-RoBERT model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TvPFeXc_AjQ_",
        "outputId": "f441985b-bbd6-4765-fb79-ac28b3c11d00",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at dkleczek/bert-base-polish-uncased-v1 were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "polbert = {\n",
        "    \"tokenizer\": BertTokenizer.from_pretrained(\"dkleczek/bert-base-polish-uncased-v1\"),\n",
        "    \"model\": BertForMaskedLM.from_pretrained(\"dkleczek/bert-base-polish-uncased-v1\")\n",
        "}\n",
        "\n",
        "def use_polbert(*parts):\n",
        "    unmasker = pipeline(\n",
        "        \"fill-mask\", \n",
        "        model=polbert[\"model\"], \n",
        "        tokenizer=polbert[\"tokenizer\"]\n",
        "    )\n",
        "    sentence = f\" {unmasker.tokenizer.mask_token} \".join(parts)\n",
        "    outputs = unmasker(sentence)\n",
        "    for i, out in enumerate(outputs):\n",
        "        print(f\"{i+1} (score = {out['score']:.3f}): {out['sequence']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VWjVboRPK00x",
        "outputId": "ee8843bc-8fc9-4f87-9230-5ffb1310c142",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 (score = 0.112): słowacki wielkim poeta był.\n",
            "2 (score = 0.095): słowacki wielkim człowiekiem był.\n",
            "3 (score = 0.066): słowacki wielkim bohaterem był.\n",
            "4 (score = 0.056): słowacki wielkim kutasem był.\n",
            "5 (score = 0.048): słowacki wielkim nie był.\n"
          ]
        }
      ],
      "source": [
        "use_polbert(\"Słowacki wielkim\", \"był.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aeSzRJgty7vp",
        "outputId": "25ca9cbd-b2d0-4d7c-a113-fcb13dd05377",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 (score = 0.275): woda wrze w 100 stopniach celsjusza.\n",
            "2 (score = 0.112): temperatura wrze w 100 stopniach celsjusza.\n",
            "3 (score = 0.045): nie wrze w 100 stopniach celsjusza.\n",
            "4 (score = 0.041): tlen wrze w 100 stopniach celsjusza.\n",
            "5 (score = 0.037): - wrze w 100 stopniach celsjusza.\n"
          ]
        }
      ],
      "source": [
        "use_polbert(\"\", \"wrze w 100 stopniach Celsjusza.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xGBiM7gvLGiZ",
        "outputId": "c5e603c4-b196-4436-b476-391c00f3fa38",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/models/auto/modeling_auto.py:1136: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
            "  FutureWarning,\n"
          ]
        }
      ],
      "source": [
        "papuga = {\n",
        "    \"model\": AutoModelWithLMHead.from_pretrained(\"flax-community/papuGaPT2\"),\n",
        "    \"tokenizer\": AutoTokenizer.from_pretrained(\"flax-community/papuGaPT2\")\n",
        "}\n",
        "\n",
        "def use_papuga(sentence: str):\n",
        "    input_ids = papuga[\"tokenizer\"].encode(sentence, return_tensors=\"pt\")\n",
        "\n",
        "    outputs = papuga[\"model\"].generate(\n",
        "        input_ids,\n",
        "        do_sample=True, \n",
        "        max_new_tokens=15, \n",
        "        top_k=50, \n",
        "        top_p=0.95, \n",
        "        num_return_sequences=5\n",
        "    )\n",
        "    sentences = [\n",
        "        papuga[\"tokenizer\"].decode(out, skip_special_tokens=True) \n",
        "        for out in outputs\n",
        "    ]\n",
        "\n",
        "    clear_output()\n",
        "    for i, s in enumerate(sentences):\n",
        "        print(f\"{i+1}: {s}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y1SE5o_y0MdV",
        "outputId": "2963b71f-cf64-4bef-f7dc-cfa7c309ef54",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1: W 100 stopniach Celsjusza wrze na rozgrzanej grzałce, co powoduje wzrost temperatury o 20 stopni Celsjusza.\n",
            "2: W 100 stopniach Celsjusza wrze z góry i w środku. Jak ostygnie - jest to tzw. wrzą\n",
            "3: W 100 stopniach Celsjusza wrze. Następnie do ciasta dodajemy startą czekoladę i mieszamy, aż do połączenia składników\n",
            "4: W 100 stopniach Celsjusza wrzeć należy 1 minutę i 10 sekund. Dodać łyżkę mąki. Mieszamy mąkę\n",
            "5: W 100 stopniach Celsjusza wrzecionko, by je podgrzać. Podgrzewam wodę do temperatury\n"
          ]
        }
      ],
      "source": [
        "use_papuga(\"W 100 stopniach Celsjusza wrze\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2m1hbElk_XpS",
        "outputId": "41048e82-3264-4ca4-886a-ae4266384251",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1: Bitwa pod Grunwaldem miała miejsce w dniach 11 – 15 lipca 1657 r. Na polach Grunwaldu miały miejsce\n",
            "2: Bitwa pod Grunwaldem miała miejsce w roku 1210. Do dziś nie wiadomo, kto pokonał Grunwald – czy\n",
            "3: Bitwa pod Grunwaldem miała miejsce w 1094 roku i trwała 12 dni, podczas których armia polsko-litewska\n",
            "4: Bitwa pod Grunwaldem miała miejsce w latach 1410–1411. Z czasem była jednak bardziej spektakularna i\n",
            "5: Bitwa pod Grunwaldem miała miejsce w 1656r. Pod Grunwaldem w 1657r. wojska krzyżackie\n"
          ]
        }
      ],
      "source": [
        "use_papuga(\"Bitwa pod Grunwaldem miała miejsce w\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "SvLWw2GGm8xU",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "roberta = {\n",
        "    \"model\": AutoModelForMaskedLM.from_pretrained(\"xlm-roberta-large\"),\n",
        "    \"tokenizer\": AutoTokenizer.from_pretrained(\"xlm-roberta-large\")\n",
        "}\n",
        "\n",
        "def use_roberta(*parts):\n",
        "    unmasker = pipeline(\n",
        "        \"fill-mask\", \n",
        "        model=roberta[\"model\"], \n",
        "        tokenizer=roberta[\"tokenizer\"]\n",
        "    )\n",
        "    sentence = f\" {unmasker.tokenizer.mask_token} \".join(parts)\n",
        "    outputs = unmasker(sentence)\n",
        "    for i, out in enumerate(outputs):\n",
        "        print(f\"{i+1} (score = {out['score']:.3f}): {out['sequence']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5k_mlcR5fhm",
        "outputId": "5e1728fd-4773-455e-f8dc-ee96fb80afae",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 (score = 0.154): Na górze słońce, na dole fiołki, a my się kochamy jak dwa aniołki.\n",
            "2 (score = 0.150): Na górze śnieg, na dole fiołki, a my się kochamy jak dwa aniołki.\n",
            "3 (score = 0.139): Na górze kwiaty, na dole fiołki, a my się kochamy jak dwa aniołki.\n",
            "4 (score = 0.080): Na górze góry, na dole fiołki, a my się kochamy jak dwa aniołki.\n",
            "5 (score = 0.018): Na górze róż, na dole fiołki, a my się kochamy jak dwa aniołki.\n"
          ]
        }
      ],
      "source": [
        "use_roberta(\"Na górze\", \", na dole fiołki, a my się kochamy jak dwa aniołki.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QA4Ugyv65rVe",
        "outputId": "fc15f6d6-d1ce-45f3-c257-afc88afc82ab",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 (score = 0.236): na gorze roze, na dole fiołki, a my sie kochamy jak dwa aniołki.\n",
            "2 (score = 0.052): na gorze kwiaty, na dole fiołki, a my sie kochamy jak dwa aniołki.\n",
            "3 (score = 0.014): na gorze lody, na dole fiołki, a my sie kochamy jak dwa aniołki.\n",
            "4 (score = 0.013): na gorze czekoladki, na dole fiołki, a my sie kochamy jak dwa aniołki.\n",
            "5 (score = 0.012): na gorze jabłka, na dole fiołki, a my sie kochamy jak dwa aniołki.\n"
          ]
        }
      ],
      "source": [
        "use_polbert(\"Na górze\", \", na dole fiołki, a my się kochamy jak dwa aniołki.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHv1bnIV_jof"
      },
      "source": [
        "## 3. Devise a method to test if the langage model understands Polish cases. Create sentences for each case."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5xofRAiDnr7"
      },
      "source": [
        "### 1. Mianownik"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0MWHNsnJ_nML",
        "outputId": "7807707c-d94c-4bc5-9925-37777d3e3105",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 (score = 0.473): słon to najwieksze zwierze na swiecie.\n",
            "2 (score = 0.102): słon to najwieksze stworzenie na swiecie.\n",
            "3 (score = 0.049): słon to najwieksze zło na swiecie.\n",
            "4 (score = 0.048): słon to najwieksze jabłko na swiecie.\n",
            "5 (score = 0.032): słon to najwieksze miasto na swiecie.\n"
          ]
        }
      ],
      "source": [
        "use_polbert(\"Słoń to największe\", \"na świecie.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VAiIRYYUAKy6",
        "outputId": "4c9a8eb6-f6ab-4018-8bf2-1281cf24d198",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 (score = 0.614): Słoń to największe słońce na świecie.\n",
            "2 (score = 0.118): Słoń to największe źródło na świecie.\n",
            "3 (score = 0.059): Słoń to największe światło na świecie.\n",
            "4 (score = 0.053): Słoń to największe ciało na świecie.\n",
            "5 (score = 0.033): Słoń to największe planeta na świecie.\n"
          ]
        }
      ],
      "source": [
        "use_roberta(\"Słoń to największe\", \"na świecie.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3KNvV3QAULc",
        "outputId": "f969094c-c595-4e14-c6f5-4478060b40c3",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1: Największe zwierze na świecie to pies rasy husky, który żyje tylko przez około 40 sekund. W tym\n",
            "2: Największe zwierze na świecie to świnka morska. Jest to zwierzę z gatunku żbików. Można spotkać\n",
            "3: Największe zwierze na świecie to lwy i delfiny. Do ich największych wrogów należą lwy morskie,\n",
            "4: Największe zwierze na świecie to pies, który w ten sposób został udomowiony, jest bardzo pło\n",
            "5: Największe zwierze na świecie to ssaki kopytne. Są one tak zróżnicowane, że stanowią o ich charakterze\n"
          ]
        }
      ],
      "source": [
        "use_papuga(\"Największe zwierze na świecie to\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqEeC8NHAevY"
      },
      "source": [
        "### 2. Dopełniacz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQyMwWNTAZ27",
        "outputId": "9e3f45d0-b32c-42ff-f475-eca6fca5e479",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 (score = 0.045): od tygodnia szukam syna, nie wiem gdzie sie podział.\n",
            "2 (score = 0.040): od tygodnia szukam chłopaka, nie wiem gdzie sie podział.\n",
            "3 (score = 0.038): od tygodnia szukam przyjaciela, nie wiem gdzie sie podział.\n",
            "4 (score = 0.028): od tygodnia szukam brata, nie wiem gdzie sie podział.\n",
            "5 (score = 0.025): od tygodnia szukam ciała, nie wiem gdzie sie podział.\n"
          ]
        }
      ],
      "source": [
        "use_polbert(\"Od tygodnia szukam\", \", nie wiem gdzie się podział.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I61dja4kAuxv",
        "outputId": "bbccce3a-0ad7-42a3-ee74-726dde8a0086",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 (score = 0.085): Od tygodnia szukam go, nie wiem gdzie się podział.\n",
            "2 (score = 0.072): Od tygodnia szukam kompa, nie wiem gdzie się podział.\n",
            "3 (score = 0.063): Od tygodnia szukam telefonu, nie wiem gdzie się podział.\n",
            "4 (score = 0.039): Od tygodnia szukam jej, nie wiem gdzie się podział.\n",
            "5 (score = 0.029): Od tygodnia szukam syna, nie wiem gdzie się podział.\n"
          ]
        }
      ],
      "source": [
        "use_roberta(\"Od tygodnia szukam\", \", nie wiem gdzie się podział.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fI8csDteAxu1",
        "outputId": "eedf3112-6f8d-4e1a-d3b7-efbb09f6a331",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1: Nie mogę znaleźć swojego. A może on jest już schowany do kieszeni i nie ma go w\n",
            "2: Nie mogę znaleźć swojego laptopa. Nie wiem, czy go oddam. Nie mam też komputera stacjonarnego\n",
            "3: Nie mogę znaleźć swojego imienia, które było by dla ciebie ciekawe i które cię fascynowało, a\n",
            "4: Nie mogę znaleźć swojego stylu pisania i stylu nie mogę. Moje dialogi są nie do końca spójne\n",
            "5: Nie mogę znaleźć swojego zdjęcia? To jest mój ulubiony blog. I mój ulubiony blog o modzie,\n"
          ]
        }
      ],
      "source": [
        "use_papuga(\"Nie mogę znaleźć swojego\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fY12ZLj7A4Ga"
      },
      "source": [
        "### 3. Celownik"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PLfC065XA0d7",
        "outputId": "67fe4c84-4684-4470-d721-dc47be37b6bf",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 (score = 0.446): dałem swojej mamie piłke.\n",
            "2 (score = 0.179): dałem swojej matce piłke.\n",
            "3 (score = 0.162): dałem swojej dziewczynie piłke.\n",
            "4 (score = 0.044): dałem swojej siostrze piłke.\n",
            "5 (score = 0.020): dałem swojej dziewczynce piłke.\n"
          ]
        }
      ],
      "source": [
        "use_polbert(\"Dałem swojej\", \"piłkę.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9gNYjE3NBXiK",
        "outputId": "96a6b57d-8f25-466c-e4e3-36c382e293b0",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 (score = 0.250): Dałem swojej stronie piłkę.\n",
            "2 (score = 0.111): Dałem swojej szkole piłkę.\n",
            "3 (score = 0.040): Dałem swojej młodzieży piłkę.\n",
            "4 (score = 0.039): Dałem swojej firmie piłkę.\n",
            "5 (score = 0.032): Dałem swojej grze piłkę.\n"
          ]
        }
      ],
      "source": [
        "use_roberta(\"Dałem swojej\", \"piłkę.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Slnz3lu2BZUc",
        "outputId": "95d99139-7b0e-41ca-a1d0-7cff3c4a52fd",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1: Przyglądam się jego pracy w internecie i muszę przyznać, że mnie też ona zachwyciła.\n",
            "2: Przyglądam się im od dłuższego czasu...Wg mnie to jest fajny zawód. Nie ma\n",
            "3: Przyglądam się sobie cotygodniowym felietonom. Tak, bardzo często widzę w nich\n",
            "4: Przyglądam się w ostatnim momencie (co za szczęście). W końcu za chwilę się obudzę\n",
            "5: Przyglądam się temu człowiekowi w nadziei, że i on sam będzie miał dzieci i rodzinę jak\n"
          ]
        }
      ],
      "source": [
        "use_papuga(\"Przyglądam się\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZuGDWMBBiUi"
      },
      "source": [
        "### 4. Biernik"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAlicKWHBmZM",
        "outputId": "5f21f66f-86d4-4dee-daf1-5fbcadab51e4",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 (score = 0.091): moja mam kupiła mi go.\n",
            "2 (score = 0.089): moja mam kupiła mi to.\n",
            "3 (score = 0.044): moja mam kupiła mi je.\n",
            "4 (score = 0.030): moja mam kupiła mi samochod.\n",
            "5 (score = 0.024): moja mam kupiła mi loda.\n"
          ]
        }
      ],
      "source": [
        "use_polbert(\"Moja mam kupiła mi\", \".\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GrCQfYSbCG2C",
        "outputId": "9fd72bb9-5429-4be6-afac-f08f34402f06",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 (score = 0.065): Moja mama kupiła mi samochód.\n",
            "2 (score = 0.059): Moja mama kupiła mi książkę.\n",
            "3 (score = 0.036): Moja mama kupiła mi to.\n",
            "4 (score = 0.035): Moja mama kupiła mi dom.\n",
            "5 (score = 0.032): Moja mama kupiła mi rower.\n"
          ]
        }
      ],
      "source": [
        "use_roberta(\"Moja mama kupiła mi\", \".\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MfYyCPD8CTqd",
        "outputId": "cf983708-f417-4da2-e1fa-3ec2bf0217e6",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1: Moja mama kupiła mi w tym sklepie i polecam z całego serca. A jak mam jeszcze problem z\n",
            "2: Moja mama kupiła mi taki model, więc od razu narobiłam batonów na śniadanie. Są\n",
            "3: Moja mama kupiła mi te świece za grosze i są one dostępne praktycznie u każdej z Was. Uważam\n",
            "4: Moja mama kupiła mi dzisiaj nowy olej i w sumie nie wiem czy bym z niego wyrobiła.\n",
            "5: Moja mama kupiła mi na urodziny nowy zestaw do manicure hybrydowego – krem o nazwie Serene\n"
          ]
        }
      ],
      "source": [
        "use_papuga(\"Moja mama kupiła mi\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgfKpE5jCZMp"
      },
      "source": [
        "### 5. Narzędnik"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2DZYqTgRCYh1",
        "outputId": "ca945283-3cda-4b9f-bbf1-38fac7c8da85",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 (score = 0.918): ta dziewczyna z długimi włosami była bardzo ładna.\n",
            "2 (score = 0.062): ta dziewczyna z długimi nogami była bardzo ładna.\n",
            "3 (score = 0.007): ta dziewczyna z długimi oczami była bardzo ładna.\n",
            "4 (score = 0.003): ta dziewczyna z długimi ustami była bardzo ładna.\n",
            "5 (score = 0.001): ta dziewczyna z długimi stopami była bardzo ładna.\n"
          ]
        }
      ],
      "source": [
        "use_polbert(\"Ta dziewczyna z długimi\", \"była bardzo ładna.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xx-fcveZCqOl",
        "outputId": "47c9f809-3598-4425-cb7e-c5cb1b0d6c93",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 (score = 0.863): Ta dziewczyna z długimi włosy była bardzo ładna.\n",
            "2 (score = 0.067): Ta dziewczyna z długimi włosów była bardzo ładna.\n",
            "3 (score = 0.012): Ta dziewczyna z długimi włos była bardzo ładna.\n",
            "4 (score = 0.011): Ta dziewczyna z długimi czasami była bardzo ładna.\n",
            "5 (score = 0.008): Ta dziewczyna z długimi bikini była bardzo ładna.\n"
          ]
        }
      ],
      "source": [
        "use_roberta(\"Ta dziewczyna z długimi\", \"była bardzo ładna.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBoD4nxeCtOt",
        "outputId": "6f440f22-a5fe-4f50-a6ef-6ac63cf258b6",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1: Bardzo spodobała mi się ta dziewczyna z długimi włosami, która jak tylko zobaczyła jej zdjęcie powiedziała, że to już koniec jej\n",
            "2: Bardzo spodobała mi się ta dziewczyna z długimi włosami! :D Nie wiem czy to dlatego że mam za długie włosy,\n",
            "3: Bardzo spodobała mi się ta dziewczyna z długimi włosami... jak to się ma do włosów? Wyglądasz w niej całkiem fajnie\n",
            "4: Bardzo spodobała mi się ta dziewczyna z długimi włosami i jest to jedna z najlepszych stylizacji jakie widziałam. Uwielbiam ten styl i\n",
            "5: Bardzo spodobała mi się ta dziewczyna z długimi włosami, w ogóle to jej się podoba, poza tym, że miała krótkie\n"
          ]
        }
      ],
      "source": [
        "use_papuga(\"Bardzo spodobała mi się ta dziewczyna z długimi\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "URAVhvhwCy4f"
      },
      "source": [
        "### 6. Miejscownik"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qNCd0gn-Cxzk",
        "outputId": "5b3f349b-15f9-440d-f8b1-77d4365eed2a",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 (score = 0.286): nie moge przestac myslec o tobie.\n",
            "2 (score = 0.068): nie moge przestac myslec o niej.\n",
            "3 (score = 0.055): nie moge przestac myslec o tym.\n",
            "4 (score = 0.037): nie moge przestac myslec o nim.\n",
            "5 (score = 0.030): nie moge przestac myslec o sobie.\n"
          ]
        }
      ],
      "source": [
        "use_polbert(\"Nie mogę przestać myśleć o\", \".\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "My15QpmQC88s",
        "outputId": "e7414231-bb50-4922-bef1-03afc7fb5d86",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 (score = 0.394): Nie mogę przestać myśleć o nim.\n",
            "2 (score = 0.174): Nie mogę przestać myśleć o tym.\n",
            "3 (score = 0.165): Nie mogę przestać myśleć o niej.\n",
            "4 (score = 0.053): Nie mogę przestać myśleć o Nim.\n",
            "5 (score = 0.022): Nie mogę przestać myśleć o nich.\n"
          ]
        }
      ],
      "source": [
        "use_roberta(\"Nie mogę przestać myśleć o\", \".\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJ3zQTdvC_SV",
        "outputId": "fb153b39-40b5-497e-8ad9-ed0984641d1d",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1: Nie mogę przestać myśleć o tym jak wspaniale bawi się w tym miejscu. To tak, jakby się tam\n",
            "2: Nie mogę przestać myśleć o tym, jak bardzo nie doceniasz mojego wkładu w edukację i dobrostanie,\n",
            "3: Nie mogę przestać myśleć o tym jak wyglądała moja przygoda z tańcem i jakie moje marzenie się spełniło\n",
            "4: Nie mogę przestać myśleć o sobie jak o zwierzęciu, a czuję się zupełnie jak ona. Zdą\n",
            "5: Nie mogę przestać myśleć o Twoich wspaniałych zdjęciach i o Twojej twórczości :) Pozdrawiam.\n",
            "Pięknie! Ale\n"
          ]
        }
      ],
      "source": [
        "use_papuga(\"Nie mogę przestać myśleć o\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rTGvFduDEJc"
      },
      "source": [
        "### 7. Wołacz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oBcwv8KpDB0U",
        "outputId": "f7bfa7e0-d6ff-4078-f141-52f8c7252f2b",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 (score = 0.132): o ty sukinsynu!\n",
            "2 (score = 0.068): o ty suko!\n",
            "3 (score = 0.045): o ty dupku!\n",
            "4 (score = 0.042): o ty draniu!\n",
            "5 (score = 0.032): o ty boze!\n"
          ]
        }
      ],
      "source": [
        "use_polbert(\"O ty\", \"!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CFpx2OOAD2L2",
        "outputId": "895864d5-a939-4562-bace-1361fdec7607",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 (score = 0.268): Święty Boże, módl się za nami.\n",
            "2 (score = 0.153): Święty Józef, módl się za nami.\n",
            "3 (score = 0.061): Święty Mikołaj, módl się za nami.\n",
            "4 (score = 0.043): Święty Andrzej, módl się za nami.\n",
            "5 (score = 0.037): Święty Stanisław, módl się za nami.\n"
          ]
        }
      ],
      "source": [
        "use_roberta(\"Święty\", \", módl się za nami.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S4BQ9Mb-D7T1",
        "outputId": "c313b253-90a7-4bca-fc07-3ab04c022191",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1: Nie rozumiesz mnie, mój chłopcze, to i ja cię proszę bardzo” - wołał Jezus na\n",
            "2: Nie rozumiesz mnie, mój przyjacielu... - w jego głosie nie było nutki zadowolenia, bo jak\n",
            "3: Nie rozumiesz mnie, mój mały ptaszku. Ja nie chcę, by wszyscy się dowiedzieli. Ja chcę\n",
            "4: Nie rozumiesz mnie, mój Boże, tak daleki jesteś od zrozumienia, że nie mogę uwierzyć. To\n",
            "5: Nie rozumiesz mnie, mój kolega to był prawdziwy leszcz. Co ciekawe miał wtedy ponad 13lat i\n"
          ]
        }
      ],
      "source": [
        "use_papuga(\"Nie rozumiesz mnie, mój\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3f1MRQWjFAMu"
      },
      "source": [
        "## 4. Devise a method to test long-range relationships such as gender. Define at least 3 sentences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJ2sqWuoEMXt",
        "outputId": "33bd11fa-2136-4169-9d82-7c2a7fa5c390",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 (score = 0.352): ta, ktora dostałam od kuby, to najładniejsza jaka widziałem w zyciu.\n",
            "2 (score = 0.067): sukienka, ktora dostałam od kuby, to najładniejsza jaka widziałem w zyciu.\n",
            "3 (score = 0.038): bransoletka, ktora dostałam od kuby, to najładniejsza jaka widziałem w zyciu.\n",
            "4 (score = 0.037): dziewczyna, ktora dostałam od kuby, to najładniejsza jaka widziałem w zyciu.\n",
            "5 (score = 0.031): kurtka, ktora dostałam od kuby, to najładniejsza jaka widziałem w zyciu.\n"
          ]
        }
      ],
      "source": [
        "use_polbert(\"\", \", którą dostałam od Kuby, to najładniejsza jaką widziałem w życiu.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "coWtOs7UFaX8",
        "outputId": "d7508b8f-72df-4ae1-c78f-20790d1ce8ca",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 (score = 0.388): Ta, którą dostałam od Kuby, to najładniejsza jaką widziałem w życiu.\n",
            "2 (score = 0.082): Karta, którą dostałam od Kuby, to najładniejsza jaką widziałem w życiu.\n",
            "3 (score = 0.051): Maska, którą dostałam od Kuby, to najładniejsza jaką widziałem w życiu.\n",
            "4 (score = 0.027): ta, którą dostałam od Kuby, to najładniejsza jaką widziałem w życiu.\n",
            "5 (score = 0.021): Kawa, którą dostałam od Kuby, to najładniejsza jaką widziałem w życiu.\n"
          ]
        }
      ],
      "source": [
        "use_roberta(\"\", \", którą dostałam od Kuby, to najładniejsza jaką widziałem w życiu.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJO0fTvSFiVV",
        "outputId": "e6cd8f51-af66-4a76-931e-6d44d00c5aa5",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1: Nigdy nie widziałam ładniejszej i co najważniejsze - na luzie, bo po raz pierwszy nie byłam w\n",
            "2: Nigdy nie widziałam ładniejszej kobiety. Jestem z Polski. Czy to na plaży? Tak. Z chęcią\n",
            "3: Nigdy nie widziałam ładniejszej i jeszcze lepiej zachowanej części ulicy z czasów okupacji. A potem się z\n",
            "4: Nigdy nie widziałam ładniejszej kobiety. Za każdym razem, kiedy ją widzę, mam ochotę uciec z tą\n",
            "5: Nigdy nie widziałam ładniejszej! 🙂 Ja też od wielu lat szyję głównie na potrzeby własne, więc nawet\n"
          ]
        }
      ],
      "source": [
        "use_papuga(\"Nigdy nie widziałam ładniejszej\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55hpDgrRFtdt",
        "outputId": "a3fbe635-b2b6-4c9d-9421-76809c47f226",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 (score = 0.688): wszystkie ofiary miały białe ubrania i czarne buty.\n",
            "2 (score = 0.128): wszystkie kobiety miały białe ubrania i czarne buty.\n",
            "3 (score = 0.048): wszystkie dziewczyny miały białe ubrania i czarne buty.\n",
            "4 (score = 0.025): wszystkie dzieci miały białe ubrania i czarne buty.\n",
            "5 (score = 0.009): wszystkie one miały białe ubrania i czarne buty.\n"
          ]
        }
      ],
      "source": [
        "use_polbert(\"Wszystkie\", \"miały białe ubrania i czarne buty.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OqdRHMuNGYIO",
        "outputId": "82e0eb07-7fd3-4973-b46b-5ac0b0d25ff8",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 (score = 0.647): Wszystkie kobiety miały białe ubrania i czarne buty.\n",
            "2 (score = 0.139): Wszystkie dzieci miały białe ubrania i czarne buty.\n",
            "3 (score = 0.027): Wszystkie modele miały białe ubrania i czarne buty.\n",
            "4 (score = 0.010): Wszystkie trzy miały białe ubrania i czarne buty.\n",
            "5 (score = 0.009): Wszystkie osoby miały białe ubrania i czarne buty.\n"
          ]
        }
      ],
      "source": [
        "use_roberta(\"Wszystkie\", \"miały białe ubrania i czarne buty.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WAeDXwrBGgtN",
        "outputId": "c2679973-2104-41eb-a084-df9d47a74c74",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1: W zamkniętym przedziale znajdują zasztyletowanego w nocy na ulicy. Jest kilka osób, które go szukają, nikt nie\n",
            "2: W zamkniętym przedziale znajdują zasztyletowanego, po długim i męczącym tygodniu. W ciągu ostatnich dni na korytarzach\n",
            "3: W zamkniętym przedziale znajdują zasztyletowanego. Na drzwiach od kabiny znajduje się krata z otworami drzwiowymi,\n",
            "4: W zamkniętym przedziale znajdują zasztyletowanego młodzieńca, jego matkę oraz starszego brata z czwórką małych dzieci, którzy\n",
            "5: W zamkniętym przedziale znajdują zasztyletowanego psa, który uciekł z ulicy, z pomocą której uratowano go przed śmiercią\n"
          ]
        }
      ],
      "source": [
        "use_papuga(\"W zamkniętym przedziale znajdują zasztyletowanego\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 166,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bk017W-TGuJm",
        "outputId": "adea58bb-a154-4e55-b59f-26012510270a",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 (score = 0.237): gdybym wiedział wtedy dokładnie to, co wiem teraz, to bym sie nie dowiedział.\n",
            "2 (score = 0.084): gdybym wiedział wtedy dokładnie to, co wiem teraz, to bym sie nie martwił.\n",
            "3 (score = 0.075): gdybym wiedział wtedy dokładnie to, co wiem teraz, to bym sie nie przyznał.\n",
            "4 (score = 0.075): gdybym wiedział wtedy dokładnie to, co wiem teraz, to bym sie nie zgodził.\n",
            "5 (score = 0.037): gdybym wiedział wtedy dokładnie to, co wiem teraz, to bym sie nie zdziwił.\n"
          ]
        }
      ],
      "source": [
        "use_polbert(\"Gdybym wiedział wtedy dokładnie to, co wiem teraz, to bym się nie\", \".\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqDjWBk8HGc_",
        "outputId": "0445d6a9-e8eb-4888-98c1-e9875145e6f0",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 (score = 0.415): Gdybym wiedział wtedy dokładnie to, co wiem teraz, to bym się nie zmienił.\n",
            "2 (score = 0.076): Gdybym wiedział wtedy dokładnie to, co wiem teraz, to bym się nie zdecydował.\n",
            "3 (score = 0.068): Gdybym wiedział wtedy dokładnie to, co wiem teraz, to bym się nie wybrał.\n",
            "4 (score = 0.057): Gdybym wiedział wtedy dokładnie to, co wiem teraz, to bym się nie pojawił.\n",
            "5 (score = 0.046): Gdybym wiedział wtedy dokładnie to, co wiem teraz, to bym się nie przygotował.\n"
          ]
        }
      ],
      "source": [
        "use_roberta(\"Gdybym wiedział wtedy dokładnie to, co wiem teraz, to bym się nie\", \".\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 164,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nSKhRAVcHLKn",
        "outputId": "a8ecc7ee-3f1c-438a-cb8c-5a623a91c705",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1: Gdybym wiedział wtedy dokładnie to, co wiem teraz, to bym się nie zgodził. Tak jak ja jestem przekonany, że jest to część procesu myślenia i\n",
            "2: Gdybym wiedział wtedy dokładnie to, co wiem teraz, to bym się nie martwił, że przez brak wiary straciłem swój udział w budowaniu tej ziemi\n",
            "3: Gdybym wiedział wtedy dokładnie to, co wiem teraz, to bym się nie zastanawiał.\n",
            "Co do tego, że coś jest dobre, to ja nie\n",
            "4: Gdybym wiedział wtedy dokładnie to, co wiem teraz, to bym się nie zgodził! (1) A wtedy Pan odpowiedział mi: Zaprawdę, mówię\n",
            "5: Gdybym wiedział wtedy dokładnie to, co wiem teraz, to bym się nie zgodził, bo gdybym wiedział z łatwością to, co wiem dziś, byłbym głup\n"
          ]
        }
      ],
      "source": [
        "use_papuga(\"Gdybym wiedział wtedy dokładnie to, co wiem teraz, to bym się nie\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kh_7iqh3H5EH"
      },
      "source": [
        "## 5. Check if the model captures real-world knowledge. Define at lest 3 sentences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {
        "id": "vRmuheEFHbBW",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "sentence = [\"Bitwa pod Grunwaldem miała miejsce w\", \"roku.\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-dBfHYAkIX_X",
        "outputId": "ad9ae922-e3ba-47f7-b530-a402c2208b65",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 (score = 0.060): bitwa pod grunwaldem miała miejsce w 1920 roku.\n",
            "2 (score = 0.037): bitwa pod grunwaldem miała miejsce w 1919 roku.\n",
            "3 (score = 0.037): bitwa pod grunwaldem miała miejsce w 1939 roku.\n",
            "4 (score = 0.029): bitwa pod grunwaldem miała miejsce w 1792 roku.\n",
            "5 (score = 0.029): bitwa pod grunwaldem miała miejsce w 1945 roku.\n"
          ]
        }
      ],
      "source": [
        "use_polbert(*sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjAc0PDGIcfX",
        "outputId": "1ac7a86e-32d5-4449-b758-65a3c84b73a9",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 (score = 0.142): Bitwa pod Grunwaldem miała miejsce w 1918 roku.\n",
            "2 (score = 0.138): Bitwa pod Grunwaldem miała miejsce w 1945 roku.\n",
            "3 (score = 0.127): Bitwa pod Grunwaldem miała miejsce w 1939 roku.\n",
            "4 (score = 0.081): Bitwa pod Grunwaldem miała miejsce w 1914 roku.\n",
            "5 (score = 0.056): Bitwa pod Grunwaldem miała miejsce w 1920 roku.\n"
          ]
        }
      ],
      "source": [
        "use_roberta(*sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9LRdgtAIeoP",
        "outputId": "b0eaae28-063a-48b8-8c0a-15fc749b34c8",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1: Bitwa pod Grunwaldem miała miejsce w 1421 roku, a jej pomysłodawcą był Jan Długosz. Jednak dopiero\n",
            "2: Bitwa pod Grunwaldem miała miejsce w latach 1410-1414. W tym czasie państwo krzyżackie było już\n",
            "3: Bitwa pod Grunwaldem miała miejsce w roku 1412, kiedy to w bitwie pod Grunwaldem wojska krzyżackie straciły\n",
            "4: Bitwa pod Grunwaldem miała miejsce w roku 1410. Król Władysław Jagiełło ogłosił ją w 1421 roku.\n",
            "5: Bitwa pod Grunwaldem miała miejsce w roku 1454, a więc mniej więcej w tym samym czasie, w którym\n"
          ]
        }
      ],
      "source": [
        "use_papuga(sentence[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {
        "id": "dK8vVtK7IqoP",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "sentence = [\"Największym kontynentem jest\", \".\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_-cpjO3JCCS",
        "outputId": "f391207c-35b3-412a-c74b-9c56b9f85b5f",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 (score = 0.118): najwiekszym kontynentem jest australia.\n",
            "2 (score = 0.049): najwiekszym kontynentem jest afryka.\n",
            "3 (score = 0.040): najwiekszym kontynentem jest ameryka.\n",
            "4 (score = 0.030): najwiekszym kontynentem jest anglia.\n",
            "5 (score = 0.030): najwiekszym kontynentem jest brazylia.\n"
          ]
        }
      ],
      "source": [
        "use_polbert(*sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hhDndk4pJCCS",
        "outputId": "c55b59db-3b8e-4e86-ac0f-20a8c74b31cf",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 (score = 0.250): Największym kontynentem jest Australia.\n",
            "2 (score = 0.132): Największym kontynentem jest Madagaskar.\n",
            "3 (score = 0.118): Największym kontynentem jest Europa.\n",
            "4 (score = 0.044): Największym kontynentem jest USA.\n",
            "5 (score = 0.034): Największym kontynentem jest India.\n"
          ]
        }
      ],
      "source": [
        "use_roberta(*sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rBiy2xIwJCCT",
        "outputId": "cf1608c1-b230-4d15-bee5-b0ae79b322dc",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1: Największym kontynentem jest oczywiście Australia, a konkretnie jej północna część - Australia Południowa (południ\n",
            "2: Największym kontynentem jest Australia, a w szczególności okolice Melbourne. Tamtejsza natura jest\n",
            "3: Największym kontynentem jest Afryka Środkowa na wysokości 1200-1300 m n.p.m\n",
            "4: Największym kontynentem jest Azja – tam ma swój początek Azję, w której można zaobserwować największą ilość\n",
            "5: Największym kontynentem jest właśnie Afryka.\n",
            "W tym regionie, jeśli się nie chce, można znaleźć\n"
          ]
        }
      ],
      "source": [
        "use_papuga(sentence[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {
        "id": "pZUbVA7OI3Ju",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "sentence = [\"Jedną z planet Układu Słonecznego jest\", \".\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_Jr4fwxJVni",
        "outputId": "7386b5ea-c885-4b14-ef71-7e3b65bd6e0f",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 (score = 0.137): jedna z planet układu słonecznego jest ziemia.\n",
            "2 (score = 0.048): jedna z planet układu słonecznego jest andromeda.\n",
            "3 (score = 0.041): jedna z planet układu słonecznego jest planeta.\n",
            "4 (score = 0.040): jedna z planet układu słonecznego jest wenus.\n",
            "5 (score = 0.028): jedna z planet układu słonecznego jest tutaj.\n"
          ]
        }
      ],
      "source": [
        "use_polbert(*sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aSrlKawyJVnj",
        "outputId": "68626ffa-5361-45e7-8984-5df009fd168a",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 (score = 0.362): Jedną z planet Układu Słonecznego jest Saturn.\n",
            "2 (score = 0.309): Jedną z planet Układu Słonecznego jest Mars.\n",
            "3 (score = 0.085): Jedną z planet Układu Słonecznego jest Jupiter.\n",
            "4 (score = 0.078): Jedną z planet Układu Słonecznego jest Neptun.\n",
            "5 (score = 0.027): Jedną z planet Układu Słonecznego jest Luna.\n"
          ]
        }
      ],
      "source": [
        "use_roberta(*sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wFN3pqA9JVnj",
        "outputId": "841a997a-fc4e-4e9d-b17b-f40f87f254a7",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1: Jedną z planet Układu Słonecznego jest Wenus, zwana także w skrócie Wenus, położona na granicy między Zie\n",
            "2: Jedną z planet Układu Słonecznego jest Księżyc, który jest obecnie najbardziej oddalonym od Ziemi ciałem niebieskim, a w\n",
            "3: Jedną z planet Układu Słonecznego jest Wenus, która jest uważana za najbardziej znaną planetę Układu Słonecznego\n",
            "4: Jedną z planet Układu Słonecznego jest kometa (Gaia), a dokładniej ich najbliższa rodzina komet.\n",
            "5: Jedną z planet Układu Słonecznego jest planeta – Słońce. Jej nazwa nawiązuje do nazwy planety oraz jej koloru.\n"
          ]
        }
      ],
      "source": [
        "use_papuga(sentence[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJinCvQvJ-fo"
      },
      "source": [
        "## 7. Answer the following questions:\n",
        "\n",
        "### a. Which of the models produced the best results?\n",
        "\n",
        "In my opinion the best results were produces by Polish BERT. Most of its guesses were matching the context and grammar.\n",
        "\n",
        "### b. Was any of the models able to capture Polish grammar?\n",
        "\n",
        "Papuga was generating sentences with mostly correct grammar. Polbert was excellent in polish cases, while Robert did some mistakes.\n",
        "\n",
        "### c. Was any of the models able to capture long-distant relationships between the words?\n",
        "\n",
        "Every model did a good job in capturing long-distance relationships beetwen the words (such as gender).\n",
        "\n",
        "### d. Was any of the models able to capture world knowledge?\n",
        "\n",
        "None of the models has a very accurate world knowledge, such as what is the biggest continent (although most guesses were continents) or in which year did the Grunwald battle take place (apart from Papuga in some guesses). But when it came to naming planets, the guesses where much closer.\n",
        "\n",
        "### e. What are the most striking errors made by the models?\n",
        "\n",
        "The most striking errors are when the model did not understand the context, and, although the form of the word is correct, it doesn't fit in the sentence. For example `Słoń to największe źródło na świecie.`, `Ta dziewczyna z długimi czasami była bardzo ładna.`. Most of such mistakes were made by the RoBERT model, which is the biggest of all three. This might be because it was trained on 94 languages while the remaining two only on Polish language."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
