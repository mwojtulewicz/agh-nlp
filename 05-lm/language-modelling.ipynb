{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Language modelling\n",
        "Mateusz Wojtulewicz"
      ],
      "metadata": {
        "id": "bdxOVe0GHwRv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Read the documentation of [Language modelling in the Transformers](https://huggingface.co/docs/transformers/task_summary#language-modeling).\n",
        "\n"
      ],
      "metadata": {
        "id": "ef7UWLtmH19W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output \n",
        "\n",
        "!pip install transformers\n",
        "!pip install sacremoses\n",
        "\n",
        "clear_output()\n",
        "print(\"Done.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZ7t37HVKEyg",
        "outputId": "21eedba7-2348-48cf-a131-d320bbf7c2db"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import (\n",
        "    AutoTokenizer, \n",
        "    AutoModelForMaskedLM, \n",
        "    AutoModelWithLMHead, \n",
        "    BertTokenizer, \n",
        "    BertForMaskedLM, \n",
        "    AutoModel,\n",
        "    pipeline\n",
        ")\n",
        "\n",
        "from pprint import pprint"
      ],
      "metadata": {
        "id": "_sxML4t-u6tO"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Download three [Polish models](https://huggingface.co/models?filter=pl) from the Huggingface repository.\n",
        "\n",
        "I'm using a Polish BERT model, a Polish GPT-2 model and a multilingual XLM-RoBERT model."
      ],
      "metadata": {
        "id": "CJMyHifsuYZf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TvPFeXc_AjQ_",
        "outputId": "f441985b-bbd6-4765-fb79-ac28b3c11d00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at dkleczek/bert-base-polish-uncased-v1 were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "polbert = {\n",
        "    \"tokenizer\": BertTokenizer.from_pretrained(\"dkleczek/bert-base-polish-uncased-v1\"),\n",
        "    \"model\": BertForMaskedLM.from_pretrained(\"dkleczek/bert-base-polish-uncased-v1\")\n",
        "}\n",
        "\n",
        "def use_polbert(*parts):\n",
        "    unmasker = pipeline(\n",
        "        \"fill-mask\", \n",
        "        model=polbert[\"model\"], \n",
        "        tokenizer=polbert[\"tokenizer\"]\n",
        "    )\n",
        "    sentence = f\" {unmasker.tokenizer.mask_token} \".join(parts)\n",
        "    outputs = unmasker(sentence)\n",
        "    for i, out in enumerate(outputs):\n",
        "        print(f\"{i+1} (score = {out['score']:.3f}): {out['sequence']}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "use_polbert(\"S≈Çowacki wielkim\", \"by≈Ç.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VWjVboRPK00x",
        "outputId": "ee8843bc-8fc9-4f87-9230-5ffb1310c142"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 (score = 0.112): s≈Çowacki wielkim poeta by≈Ç.\n",
            "2 (score = 0.095): s≈Çowacki wielkim cz≈Çowiekiem by≈Ç.\n",
            "3 (score = 0.066): s≈Çowacki wielkim bohaterem by≈Ç.\n",
            "4 (score = 0.056): s≈Çowacki wielkim kutasem by≈Ç.\n",
            "5 (score = 0.048): s≈Çowacki wielkim nie by≈Ç.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "use_polbert(\"\", \"wrze w 100 stopniach Celsjusza.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aeSzRJgty7vp",
        "outputId": "25ca9cbd-b2d0-4d7c-a113-fcb13dd05377"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 (score = 0.275): woda wrze w 100 stopniach celsjusza.\n",
            "2 (score = 0.112): temperatura wrze w 100 stopniach celsjusza.\n",
            "3 (score = 0.045): nie wrze w 100 stopniach celsjusza.\n",
            "4 (score = 0.041): tlen wrze w 100 stopniach celsjusza.\n",
            "5 (score = 0.037): - wrze w 100 stopniach celsjusza.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "papuga = {\n",
        "    \"model\": AutoModelWithLMHead.from_pretrained(\"flax-community/papuGaPT2\"),\n",
        "    \"tokenizer\": AutoTokenizer.from_pretrained(\"flax-community/papuGaPT2\")\n",
        "}\n",
        "\n",
        "def use_papuga(sentence: str):\n",
        "    input_ids = papuga[\"tokenizer\"].encode(sentence, return_tensors=\"pt\")\n",
        "\n",
        "    outputs = papuga[\"model\"].generate(\n",
        "        input_ids,\n",
        "        do_sample=True, \n",
        "        max_new_tokens=15, \n",
        "        top_k=50, \n",
        "        top_p=0.95, \n",
        "        num_return_sequences=5\n",
        "    )\n",
        "    sentences = [\n",
        "        papuga[\"tokenizer\"].decode(out, skip_special_tokens=True) \n",
        "        for out in outputs\n",
        "    ]\n",
        "\n",
        "    clear_output()\n",
        "    for i, s in enumerate(sentences):\n",
        "        print(f\"{i+1}: {s}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xGBiM7gvLGiZ",
        "outputId": "c5e603c4-b196-4436-b476-391c00f3fa38"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/models/auto/modeling_auto.py:1136: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "use_papuga(\"W 100 stopniach Celsjusza wrze\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y1SE5o_y0MdV",
        "outputId": "2963b71f-cf64-4bef-f7dc-cfa7c309ef54"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1: W 100 stopniach Celsjusza wrze na rozgrzanej grza≈Çce, co powoduje wzrost temperatury o 20 stopni Celsjusza.\n",
            "2: W 100 stopniach Celsjusza wrze z g√≥ry i w ≈õrodku. Jak ostygnie - jest to tzw. wrzƒÖ\n",
            "3: W 100 stopniach Celsjusza wrze. Nastƒôpnie do ciasta dodajemy startƒÖ czekoladƒô i mieszamy, a≈º do po≈ÇƒÖczenia sk≈Çadnik√≥w\n",
            "4: W 100 stopniach Celsjusza wrzeƒá nale≈ºy 1 minutƒô i 10 sekund. Dodaƒá ≈Çy≈ºkƒô mƒÖki. Mieszamy mƒÖkƒô\n",
            "5: W 100 stopniach Celsjusza wrzecionko, by je podgrzaƒá. Podgrzewam wodƒô do temperatury\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "use_papuga(\"Bitwa pod Grunwaldem mia≈Ça miejsce w\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2m1hbElk_XpS",
        "outputId": "41048e82-3264-4ca4-886a-ae4266384251"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1: Bitwa pod Grunwaldem mia≈Ça miejsce w dniach 11 ‚Äì 15 lipca 1657 r. Na polach Grunwaldu mia≈Çy miejsce\n",
            "2: Bitwa pod Grunwaldem mia≈Ça miejsce w roku 1210. Do dzi≈õ nie wiadomo, kto pokona≈Ç Grunwald ‚Äì czy\n",
            "3: Bitwa pod Grunwaldem mia≈Ça miejsce w 1094 roku i trwa≈Ça 12 dni, podczas kt√≥rych armia polsko-litewska\n",
            "4: Bitwa pod Grunwaldem mia≈Ça miejsce w latach 1410‚Äì1411. Z czasem by≈Ça jednak bardziej spektakularna i\n",
            "5: Bitwa pod Grunwaldem mia≈Ça miejsce w 1656r. Pod Grunwaldem w 1657r. wojska krzy≈ºackie\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "roberta = {\n",
        "    \"model\": AutoModelForMaskedLM.from_pretrained(\"xlm-roberta-large\"),\n",
        "    \"tokenizer\": AutoTokenizer.from_pretrained(\"xlm-roberta-large\")\n",
        "}\n",
        "\n",
        "def use_roberta(*parts):\n",
        "    unmasker = pipeline(\n",
        "        \"fill-mask\", \n",
        "        model=roberta[\"model\"], \n",
        "        tokenizer=roberta[\"tokenizer\"]\n",
        "    )\n",
        "    sentence = f\" {unmasker.tokenizer.mask_token} \".join(parts)\n",
        "    outputs = unmasker(sentence)\n",
        "    for i, out in enumerate(outputs):\n",
        "        print(f\"{i+1} (score = {out['score']:.3f}): {out['sequence']}\")"
      ],
      "metadata": {
        "id": "SvLWw2GGm8xU"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "use_roberta(\"Na g√≥rze\", \", na dole fio≈Çki, a my siƒô kochamy jak dwa anio≈Çki.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5k_mlcR5fhm",
        "outputId": "5e1728fd-4773-455e-f8dc-ee96fb80afae"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 (score = 0.154): Na g√≥rze s≈Ço≈Ñce, na dole fio≈Çki, a my siƒô kochamy jak dwa anio≈Çki.\n",
            "2 (score = 0.150): Na g√≥rze ≈õnieg, na dole fio≈Çki, a my siƒô kochamy jak dwa anio≈Çki.\n",
            "3 (score = 0.139): Na g√≥rze kwiaty, na dole fio≈Çki, a my siƒô kochamy jak dwa anio≈Çki.\n",
            "4 (score = 0.080): Na g√≥rze g√≥ry, na dole fio≈Çki, a my siƒô kochamy jak dwa anio≈Çki.\n",
            "5 (score = 0.018): Na g√≥rze r√≥≈º, na dole fio≈Çki, a my siƒô kochamy jak dwa anio≈Çki.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "use_polbert(\"Na g√≥rze\", \", na dole fio≈Çki, a my siƒô kochamy jak dwa anio≈Çki.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QA4Ugyv65rVe",
        "outputId": "fc15f6d6-d1ce-45f3-c257-afc88afc82ab"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 (score = 0.236): na gorze roze, na dole fio≈Çki, a my sie kochamy jak dwa anio≈Çki.\n",
            "2 (score = 0.052): na gorze kwiaty, na dole fio≈Çki, a my sie kochamy jak dwa anio≈Çki.\n",
            "3 (score = 0.014): na gorze lody, na dole fio≈Çki, a my sie kochamy jak dwa anio≈Çki.\n",
            "4 (score = 0.013): na gorze czekoladki, na dole fio≈Çki, a my sie kochamy jak dwa anio≈Çki.\n",
            "5 (score = 0.012): na gorze jab≈Çka, na dole fio≈Çki, a my sie kochamy jak dwa anio≈Çki.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Devise a method to test if the langage model understands Polish cases. Create sentences for each case."
      ],
      "metadata": {
        "id": "gHv1bnIV_jof"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Mianownik"
      ],
      "metadata": {
        "id": "s5xofRAiDnr7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "use_polbert(\"S≈Ço≈Ñ to najwiƒôksze\", \"na ≈õwiecie.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0MWHNsnJ_nML",
        "outputId": "7807707c-d94c-4bc5-9925-37777d3e3105"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 (score = 0.473): s≈Çon to najwieksze zwierze na swiecie.\n",
            "2 (score = 0.102): s≈Çon to najwieksze stworzenie na swiecie.\n",
            "3 (score = 0.049): s≈Çon to najwieksze z≈Ço na swiecie.\n",
            "4 (score = 0.048): s≈Çon to najwieksze jab≈Çko na swiecie.\n",
            "5 (score = 0.032): s≈Çon to najwieksze miasto na swiecie.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "use_roberta(\"S≈Ço≈Ñ to najwiƒôksze\", \"na ≈õwiecie.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VAiIRYYUAKy6",
        "outputId": "4c9a8eb6-f6ab-4018-8bf2-1281cf24d198"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 (score = 0.614): S≈Ço≈Ñ to najwiƒôksze s≈Ço≈Ñce na ≈õwiecie.\n",
            "2 (score = 0.118): S≈Ço≈Ñ to najwiƒôksze ≈∫r√≥d≈Ço na ≈õwiecie.\n",
            "3 (score = 0.059): S≈Ço≈Ñ to najwiƒôksze ≈õwiat≈Ço na ≈õwiecie.\n",
            "4 (score = 0.053): S≈Ço≈Ñ to najwiƒôksze cia≈Ço na ≈õwiecie.\n",
            "5 (score = 0.033): S≈Ço≈Ñ to najwiƒôksze planeta na ≈õwiecie.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "use_papuga(\"Najwiƒôksze zwierze na ≈õwiecie to\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3KNvV3QAULc",
        "outputId": "f969094c-c595-4e14-c6f5-4478060b40c3"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1: Najwiƒôksze zwierze na ≈õwiecie to pies rasy husky, kt√≥ry ≈ºyje tylko przez oko≈Ço 40 sekund. W tym\n",
            "2: Najwiƒôksze zwierze na ≈õwiecie to ≈õwinka morska. Jest to zwierzƒô z gatunku ≈ºbik√≥w. Mo≈ºna spotkaƒá\n",
            "3: Najwiƒôksze zwierze na ≈õwiecie to lwy i delfiny. Do ich najwiƒôkszych wrog√≥w nale≈ºƒÖ lwy morskie,\n",
            "4: Najwiƒôksze zwierze na ≈õwiecie to pies, kt√≥ry w ten spos√≥b zosta≈Ç udomowiony, jest bardzo p≈Ço\n",
            "5: Najwiƒôksze zwierze na ≈õwiecie to ssaki kopytne. SƒÖ one tak zr√≥≈ºnicowane, ≈ºe stanowiƒÖ o ich charakterze\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Dope≈Çniacz"
      ],
      "metadata": {
        "id": "kqEeC8NHAevY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "use_polbert(\"Od tygodnia szukam\", \", nie wiem gdzie siƒô podzia≈Ç.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQyMwWNTAZ27",
        "outputId": "9e3f45d0-b32c-42ff-f475-eca6fca5e479"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 (score = 0.045): od tygodnia szukam syna, nie wiem gdzie sie podzia≈Ç.\n",
            "2 (score = 0.040): od tygodnia szukam ch≈Çopaka, nie wiem gdzie sie podzia≈Ç.\n",
            "3 (score = 0.038): od tygodnia szukam przyjaciela, nie wiem gdzie sie podzia≈Ç.\n",
            "4 (score = 0.028): od tygodnia szukam brata, nie wiem gdzie sie podzia≈Ç.\n",
            "5 (score = 0.025): od tygodnia szukam cia≈Ça, nie wiem gdzie sie podzia≈Ç.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "use_roberta(\"Od tygodnia szukam\", \", nie wiem gdzie siƒô podzia≈Ç.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbccce3a-0ad7-42a3-ee74-726dde8a0086",
        "id": "I61dja4kAuxv"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 (score = 0.085): Od tygodnia szukam go, nie wiem gdzie siƒô podzia≈Ç.\n",
            "2 (score = 0.072): Od tygodnia szukam kompa, nie wiem gdzie siƒô podzia≈Ç.\n",
            "3 (score = 0.063): Od tygodnia szukam telefonu, nie wiem gdzie siƒô podzia≈Ç.\n",
            "4 (score = 0.039): Od tygodnia szukam jej, nie wiem gdzie siƒô podzia≈Ç.\n",
            "5 (score = 0.029): Od tygodnia szukam syna, nie wiem gdzie siƒô podzia≈Ç.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "use_papuga(\"Nie mogƒô znale≈∫ƒá swojego\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fI8csDteAxu1",
        "outputId": "eedf3112-6f8d-4e1a-d3b7-efbb09f6a331"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1: Nie mogƒô znale≈∫ƒá swojego. A mo≈ºe on jest ju≈º schowany do kieszeni i nie ma go w\n",
            "2: Nie mogƒô znale≈∫ƒá swojego laptopa. Nie wiem, czy go oddam. Nie mam te≈º komputera stacjonarnego\n",
            "3: Nie mogƒô znale≈∫ƒá swojego imienia, kt√≥re by≈Ço by dla ciebie ciekawe i kt√≥re ciƒô fascynowa≈Ço, a\n",
            "4: Nie mogƒô znale≈∫ƒá swojego stylu pisania i stylu nie mogƒô. Moje dialogi sƒÖ nie do ko≈Ñca sp√≥jne\n",
            "5: Nie mogƒô znale≈∫ƒá swojego zdjƒôcia? To jest m√≥j ulubiony blog. I m√≥j ulubiony blog o modzie,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Celownik"
      ],
      "metadata": {
        "id": "fY12ZLj7A4Ga"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "use_polbert(\"Da≈Çem swojej\", \"pi≈Çkƒô.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PLfC065XA0d7",
        "outputId": "67fe4c84-4684-4470-d721-dc47be37b6bf"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 (score = 0.446): da≈Çem swojej mamie pi≈Çke.\n",
            "2 (score = 0.179): da≈Çem swojej matce pi≈Çke.\n",
            "3 (score = 0.162): da≈Çem swojej dziewczynie pi≈Çke.\n",
            "4 (score = 0.044): da≈Çem swojej siostrze pi≈Çke.\n",
            "5 (score = 0.020): da≈Çem swojej dziewczynce pi≈Çke.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "use_roberta(\"Da≈Çem swojej\", \"pi≈Çkƒô.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9gNYjE3NBXiK",
        "outputId": "96a6b57d-8f25-466c-e4e3-36c382e293b0"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 (score = 0.250): Da≈Çem swojej stronie pi≈Çkƒô.\n",
            "2 (score = 0.111): Da≈Çem swojej szkole pi≈Çkƒô.\n",
            "3 (score = 0.040): Da≈Çem swojej m≈Çodzie≈ºy pi≈Çkƒô.\n",
            "4 (score = 0.039): Da≈Çem swojej firmie pi≈Çkƒô.\n",
            "5 (score = 0.032): Da≈Çem swojej grze pi≈Çkƒô.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "use_papuga(\"PrzyglƒÖdam siƒô\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Slnz3lu2BZUc",
        "outputId": "95d99139-7b0e-41ca-a1d0-7cff3c4a52fd"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1: PrzyglƒÖdam siƒô jego pracy w internecie i muszƒô przyznaƒá, ≈ºe mnie te≈º ona zachwyci≈Ça.\n",
            "2: PrzyglƒÖdam siƒô im od d≈Çu≈ºszego czasu...Wg mnie to jest fajny zaw√≥d. Nie ma\n",
            "3: PrzyglƒÖdam siƒô sobie cotygodniowym felietonom. Tak, bardzo czƒôsto widzƒô w nich\n",
            "4: PrzyglƒÖdam siƒô w ostatnim momencie (co za szczƒô≈õcie). W ko≈Ñcu za chwilƒô siƒô obudzƒô\n",
            "5: PrzyglƒÖdam siƒô temu cz≈Çowiekowi w nadziei, ≈ºe i on sam bƒôdzie mia≈Ç dzieci i rodzinƒô jak\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Biernik"
      ],
      "metadata": {
        "id": "uZuGDWMBBiUi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "use_polbert(\"Moja mam kupi≈Ça mi\", \".\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAlicKWHBmZM",
        "outputId": "5f21f66f-86d4-4dee-daf1-5fbcadab51e4"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 (score = 0.091): moja mam kupi≈Ça mi go.\n",
            "2 (score = 0.089): moja mam kupi≈Ça mi to.\n",
            "3 (score = 0.044): moja mam kupi≈Ça mi je.\n",
            "4 (score = 0.030): moja mam kupi≈Ça mi samochod.\n",
            "5 (score = 0.024): moja mam kupi≈Ça mi loda.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "use_roberta(\"Moja mama kupi≈Ça mi\", \".\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GrCQfYSbCG2C",
        "outputId": "9fd72bb9-5429-4be6-afac-f08f34402f06"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 (score = 0.065): Moja mama kupi≈Ça mi samoch√≥d.\n",
            "2 (score = 0.059): Moja mama kupi≈Ça mi ksiƒÖ≈ºkƒô.\n",
            "3 (score = 0.036): Moja mama kupi≈Ça mi to.\n",
            "4 (score = 0.035): Moja mama kupi≈Ça mi dom.\n",
            "5 (score = 0.032): Moja mama kupi≈Ça mi rower.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "use_papuga(\"Moja mama kupi≈Ça mi\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MfYyCPD8CTqd",
        "outputId": "cf983708-f417-4da2-e1fa-3ec2bf0217e6"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1: Moja mama kupi≈Ça mi w tym sklepie i polecam z ca≈Çego serca. A jak mam jeszcze problem z\n",
            "2: Moja mama kupi≈Ça mi taki model, wiƒôc od razu narobi≈Çam baton√≥w na ≈õniadanie. SƒÖ\n",
            "3: Moja mama kupi≈Ça mi te ≈õwiece za grosze i sƒÖ one dostƒôpne praktycznie u ka≈ºdej z Was. Uwa≈ºam\n",
            "4: Moja mama kupi≈Ça mi dzisiaj nowy olej i w sumie nie wiem czy bym z niego wyrobi≈Ça.\n",
            "5: Moja mama kupi≈Ça mi na urodziny nowy zestaw do manicure hybrydowego ‚Äì krem o nazwie Serene\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Narzƒôdnik"
      ],
      "metadata": {
        "id": "EgfKpE5jCZMp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "use_polbert(\"Ta dziewczyna z d≈Çugimi\", \"by≈Ça bardzo ≈Çadna.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2DZYqTgRCYh1",
        "outputId": "ca945283-3cda-4b9f-bbf1-38fac7c8da85"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 (score = 0.918): ta dziewczyna z d≈Çugimi w≈Çosami by≈Ça bardzo ≈Çadna.\n",
            "2 (score = 0.062): ta dziewczyna z d≈Çugimi nogami by≈Ça bardzo ≈Çadna.\n",
            "3 (score = 0.007): ta dziewczyna z d≈Çugimi oczami by≈Ça bardzo ≈Çadna.\n",
            "4 (score = 0.003): ta dziewczyna z d≈Çugimi ustami by≈Ça bardzo ≈Çadna.\n",
            "5 (score = 0.001): ta dziewczyna z d≈Çugimi stopami by≈Ça bardzo ≈Çadna.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "use_roberta(\"Ta dziewczyna z d≈Çugimi\", \"by≈Ça bardzo ≈Çadna.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xx-fcveZCqOl",
        "outputId": "47c9f809-3598-4425-cb7e-c5cb1b0d6c93"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 (score = 0.863): Ta dziewczyna z d≈Çugimi w≈Çosy by≈Ça bardzo ≈Çadna.\n",
            "2 (score = 0.067): Ta dziewczyna z d≈Çugimi w≈Ços√≥w by≈Ça bardzo ≈Çadna.\n",
            "3 (score = 0.012): Ta dziewczyna z d≈Çugimi w≈Ços by≈Ça bardzo ≈Çadna.\n",
            "4 (score = 0.011): Ta dziewczyna z d≈Çugimi czasami by≈Ça bardzo ≈Çadna.\n",
            "5 (score = 0.008): Ta dziewczyna z d≈Çugimi bikini by≈Ça bardzo ≈Çadna.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "use_papuga(\"Bardzo spodoba≈Ça mi siƒô ta dziewczyna z d≈Çugimi\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBoD4nxeCtOt",
        "outputId": "6f440f22-a5fe-4f50-a6ef-6ac63cf258b6"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1: Bardzo spodoba≈Ça mi siƒô ta dziewczyna z d≈Çugimi w≈Çosami, kt√≥ra jak tylko zobaczy≈Ça jej zdjƒôcie powiedzia≈Ça, ≈ºe to ju≈º koniec jej\n",
            "2: Bardzo spodoba≈Ça mi siƒô ta dziewczyna z d≈Çugimi w≈Çosami! :D Nie wiem czy to dlatego ≈ºe mam za d≈Çugie w≈Çosy,\n",
            "3: Bardzo spodoba≈Ça mi siƒô ta dziewczyna z d≈Çugimi w≈Çosami... jak to siƒô ma do w≈Ços√≥w? WyglƒÖdasz w niej ca≈Çkiem fajnie\n",
            "4: Bardzo spodoba≈Ça mi siƒô ta dziewczyna z d≈Çugimi w≈Çosami i jest to jedna z najlepszych stylizacji jakie widzia≈Çam. Uwielbiam ten styl i\n",
            "5: Bardzo spodoba≈Ça mi siƒô ta dziewczyna z d≈Çugimi w≈Çosami, w og√≥le to jej siƒô podoba, poza tym, ≈ºe mia≈Ça kr√≥tkie\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Miejscownik"
      ],
      "metadata": {
        "id": "URAVhvhwCy4f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "use_polbert(\"Nie mogƒô przestaƒá my≈õleƒá o\", \".\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qNCd0gn-Cxzk",
        "outputId": "5b3f349b-15f9-440d-f8b1-77d4365eed2a"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 (score = 0.286): nie moge przestac myslec o tobie.\n",
            "2 (score = 0.068): nie moge przestac myslec o niej.\n",
            "3 (score = 0.055): nie moge przestac myslec o tym.\n",
            "4 (score = 0.037): nie moge przestac myslec o nim.\n",
            "5 (score = 0.030): nie moge przestac myslec o sobie.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "use_roberta(\"Nie mogƒô przestaƒá my≈õleƒá o\", \".\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "My15QpmQC88s",
        "outputId": "e7414231-bb50-4922-bef1-03afc7fb5d86"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 (score = 0.394): Nie mogƒô przestaƒá my≈õleƒá o nim.\n",
            "2 (score = 0.174): Nie mogƒô przestaƒá my≈õleƒá o tym.\n",
            "3 (score = 0.165): Nie mogƒô przestaƒá my≈õleƒá o niej.\n",
            "4 (score = 0.053): Nie mogƒô przestaƒá my≈õleƒá o Nim.\n",
            "5 (score = 0.022): Nie mogƒô przestaƒá my≈õleƒá o nich.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "use_papuga(\"Nie mogƒô przestaƒá my≈õleƒá o\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJ3zQTdvC_SV",
        "outputId": "fb153b39-40b5-497e-8ad9-ed0984641d1d"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1: Nie mogƒô przestaƒá my≈õleƒá o tym jak wspaniale bawi siƒô w tym miejscu. To tak, jakby siƒô tam\n",
            "2: Nie mogƒô przestaƒá my≈õleƒá o tym, jak bardzo nie doceniasz mojego wk≈Çadu w edukacjƒô i dobrostanie,\n",
            "3: Nie mogƒô przestaƒá my≈õleƒá o tym jak wyglƒÖda≈Ça moja przygoda z ta≈Ñcem i jakie moje marzenie siƒô spe≈Çni≈Ço\n",
            "4: Nie mogƒô przestaƒá my≈õleƒá o sobie jak o zwierzƒôciu, a czujƒô siƒô zupe≈Çnie jak ona. ZdƒÖ\n",
            "5: Nie mogƒô przestaƒá my≈õleƒá o Twoich wspania≈Çych zdjƒôciach i o Twojej tw√≥rczo≈õci :) Pozdrawiam.\n",
            "Piƒôknie! Ale\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Wo≈Çacz"
      ],
      "metadata": {
        "id": "0rTGvFduDEJc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "use_polbert(\"O ty\", \"!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oBcwv8KpDB0U",
        "outputId": "f7bfa7e0-d6ff-4078-f141-52f8c7252f2b"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 (score = 0.132): o ty sukinsynu!\n",
            "2 (score = 0.068): o ty suko!\n",
            "3 (score = 0.045): o ty dupku!\n",
            "4 (score = 0.042): o ty draniu!\n",
            "5 (score = 0.032): o ty boze!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "use_roberta(\"≈öwiƒôty\", \", m√≥dl siƒô za nami.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CFpx2OOAD2L2",
        "outputId": "895864d5-a939-4562-bace-1361fdec7607"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 (score = 0.268): ≈öwiƒôty Bo≈ºe, m√≥dl siƒô za nami.\n",
            "2 (score = 0.153): ≈öwiƒôty J√≥zef, m√≥dl siƒô za nami.\n",
            "3 (score = 0.061): ≈öwiƒôty Miko≈Çaj, m√≥dl siƒô za nami.\n",
            "4 (score = 0.043): ≈öwiƒôty Andrzej, m√≥dl siƒô za nami.\n",
            "5 (score = 0.037): ≈öwiƒôty Stanis≈Çaw, m√≥dl siƒô za nami.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "use_papuga(\"Nie rozumiesz mnie, m√≥j\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S4BQ9Mb-D7T1",
        "outputId": "c313b253-90a7-4bca-fc07-3ab04c022191"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1: Nie rozumiesz mnie, m√≥j ch≈Çopcze, to i ja ciƒô proszƒô bardzo‚Äù - wo≈Ça≈Ç Jezus na\n",
            "2: Nie rozumiesz mnie, m√≥j przyjacielu... - w jego g≈Çosie nie by≈Ço nutki zadowolenia, bo jak\n",
            "3: Nie rozumiesz mnie, m√≥j ma≈Çy ptaszku. Ja nie chcƒô, by wszyscy siƒô dowiedzieli. Ja chcƒô\n",
            "4: Nie rozumiesz mnie, m√≥j Bo≈ºe, tak daleki jeste≈õ od zrozumienia, ≈ºe nie mogƒô uwierzyƒá. To\n",
            "5: Nie rozumiesz mnie, m√≥j kolega to by≈Ç prawdziwy leszcz. Co ciekawe mia≈Ç wtedy ponad 13lat i\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Devise a method to test long-range relationships such as gender. Define at least 3 sentences."
      ],
      "metadata": {
        "id": "3f1MRQWjFAMu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "use_polbert(\"\", \", kt√≥rƒÖ dosta≈Çam od Kuby, to naj≈Çadniejsza jakƒÖ widzia≈Çem w ≈ºyciu.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJ2sqWuoEMXt",
        "outputId": "33bd11fa-2136-4169-9d82-7c2a7fa5c390"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 (score = 0.352): ta, ktora dosta≈Çam od kuby, to naj≈Çadniejsza jaka widzia≈Çem w zyciu.\n",
            "2 (score = 0.067): sukienka, ktora dosta≈Çam od kuby, to naj≈Çadniejsza jaka widzia≈Çem w zyciu.\n",
            "3 (score = 0.038): bransoletka, ktora dosta≈Çam od kuby, to naj≈Çadniejsza jaka widzia≈Çem w zyciu.\n",
            "4 (score = 0.037): dziewczyna, ktora dosta≈Çam od kuby, to naj≈Çadniejsza jaka widzia≈Çem w zyciu.\n",
            "5 (score = 0.031): kurtka, ktora dosta≈Çam od kuby, to naj≈Çadniejsza jaka widzia≈Çem w zyciu.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "use_roberta(\"\", \", kt√≥rƒÖ dosta≈Çam od Kuby, to naj≈Çadniejsza jakƒÖ widzia≈Çem w ≈ºyciu.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "coWtOs7UFaX8",
        "outputId": "d7508b8f-72df-4ae1-c78f-20790d1ce8ca"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 (score = 0.388): Ta, kt√≥rƒÖ dosta≈Çam od Kuby, to naj≈Çadniejsza jakƒÖ widzia≈Çem w ≈ºyciu.\n",
            "2 (score = 0.082): Karta, kt√≥rƒÖ dosta≈Çam od Kuby, to naj≈Çadniejsza jakƒÖ widzia≈Çem w ≈ºyciu.\n",
            "3 (score = 0.051): Maska, kt√≥rƒÖ dosta≈Çam od Kuby, to naj≈Çadniejsza jakƒÖ widzia≈Çem w ≈ºyciu.\n",
            "4 (score = 0.027): ta, kt√≥rƒÖ dosta≈Çam od Kuby, to naj≈Çadniejsza jakƒÖ widzia≈Çem w ≈ºyciu.\n",
            "5 (score = 0.021): Kawa, kt√≥rƒÖ dosta≈Çam od Kuby, to naj≈Çadniejsza jakƒÖ widzia≈Çem w ≈ºyciu.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "use_papuga(\"Nigdy nie widzia≈Çam ≈Çadniejszej\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJO0fTvSFiVV",
        "outputId": "e6cd8f51-af66-4a76-931e-6d44d00c5aa5"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1: Nigdy nie widzia≈Çam ≈Çadniejszej i co najwa≈ºniejsze - na luzie, bo po raz pierwszy nie by≈Çam w\n",
            "2: Nigdy nie widzia≈Çam ≈Çadniejszej kobiety. Jestem z Polski. Czy to na pla≈ºy? Tak. Z chƒôciƒÖ\n",
            "3: Nigdy nie widzia≈Çam ≈Çadniejszej i jeszcze lepiej zachowanej czƒô≈õci ulicy z czas√≥w okupacji. A potem siƒô z\n",
            "4: Nigdy nie widzia≈Çam ≈Çadniejszej kobiety. Za ka≈ºdym razem, kiedy jƒÖ widzƒô, mam ochotƒô uciec z tƒÖ\n",
            "5: Nigdy nie widzia≈Çam ≈Çadniejszej! üôÇ Ja te≈º od wielu lat szyjƒô g≈Ç√≥wnie na potrzeby w≈Çasne, wiƒôc nawet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "use_polbert(\"Wszystkie\", \"mia≈Çy bia≈Çe ubrania i czarne buty.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55hpDgrRFtdt",
        "outputId": "a3fbe635-b2b6-4c9d-9421-76809c47f226"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 (score = 0.688): wszystkie ofiary mia≈Çy bia≈Çe ubrania i czarne buty.\n",
            "2 (score = 0.128): wszystkie kobiety mia≈Çy bia≈Çe ubrania i czarne buty.\n",
            "3 (score = 0.048): wszystkie dziewczyny mia≈Çy bia≈Çe ubrania i czarne buty.\n",
            "4 (score = 0.025): wszystkie dzieci mia≈Çy bia≈Çe ubrania i czarne buty.\n",
            "5 (score = 0.009): wszystkie one mia≈Çy bia≈Çe ubrania i czarne buty.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "use_roberta(\"Wszystkie\", \"mia≈Çy bia≈Çe ubrania i czarne buty.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OqdRHMuNGYIO",
        "outputId": "82e0eb07-7fd3-4973-b46b-5ac0b0d25ff8"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 (score = 0.647): Wszystkie kobiety mia≈Çy bia≈Çe ubrania i czarne buty.\n",
            "2 (score = 0.139): Wszystkie dzieci mia≈Çy bia≈Çe ubrania i czarne buty.\n",
            "3 (score = 0.027): Wszystkie modele mia≈Çy bia≈Çe ubrania i czarne buty.\n",
            "4 (score = 0.010): Wszystkie trzy mia≈Çy bia≈Çe ubrania i czarne buty.\n",
            "5 (score = 0.009): Wszystkie osoby mia≈Çy bia≈Çe ubrania i czarne buty.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "use_papuga(\"W zamkniƒôtym przedziale znajdujƒÖ zasztyletowanego\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WAeDXwrBGgtN",
        "outputId": "c2679973-2104-41eb-a084-df9d47a74c74"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1: W zamkniƒôtym przedziale znajdujƒÖ zasztyletowanego w nocy na ulicy. Jest kilka os√≥b, kt√≥re go szukajƒÖ, nikt nie\n",
            "2: W zamkniƒôtym przedziale znajdujƒÖ zasztyletowanego, po d≈Çugim i mƒôczƒÖcym tygodniu. W ciƒÖgu ostatnich dni na korytarzach\n",
            "3: W zamkniƒôtym przedziale znajdujƒÖ zasztyletowanego. Na drzwiach od kabiny znajduje siƒô krata z otworami drzwiowymi,\n",
            "4: W zamkniƒôtym przedziale znajdujƒÖ zasztyletowanego m≈Çodzie≈Ñca, jego matkƒô oraz starszego brata z czw√≥rkƒÖ ma≈Çych dzieci, kt√≥rzy\n",
            "5: W zamkniƒôtym przedziale znajdujƒÖ zasztyletowanego psa, kt√≥ry uciek≈Ç z ulicy, z pomocƒÖ kt√≥rej uratowano go przed ≈õmierciƒÖ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "use_polbert(\"Gdybym wiedzia≈Ç wtedy dok≈Çadnie to, co wiem teraz, to bym siƒô nie\", \".\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bk017W-TGuJm",
        "outputId": "adea58bb-a154-4e55-b59f-26012510270a"
      },
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 (score = 0.237): gdybym wiedzia≈Ç wtedy dok≈Çadnie to, co wiem teraz, to bym sie nie dowiedzia≈Ç.\n",
            "2 (score = 0.084): gdybym wiedzia≈Ç wtedy dok≈Çadnie to, co wiem teraz, to bym sie nie martwi≈Ç.\n",
            "3 (score = 0.075): gdybym wiedzia≈Ç wtedy dok≈Çadnie to, co wiem teraz, to bym sie nie przyzna≈Ç.\n",
            "4 (score = 0.075): gdybym wiedzia≈Ç wtedy dok≈Çadnie to, co wiem teraz, to bym sie nie zgodzi≈Ç.\n",
            "5 (score = 0.037): gdybym wiedzia≈Ç wtedy dok≈Çadnie to, co wiem teraz, to bym sie nie zdziwi≈Ç.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "use_roberta(\"Gdybym wiedzia≈Ç wtedy dok≈Çadnie to, co wiem teraz, to bym siƒô nie\", \".\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqDjWBk8HGc_",
        "outputId": "0445d6a9-e8eb-4888-98c1-e9875145e6f0"
      },
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 (score = 0.415): Gdybym wiedzia≈Ç wtedy dok≈Çadnie to, co wiem teraz, to bym siƒô nie zmieni≈Ç.\n",
            "2 (score = 0.076): Gdybym wiedzia≈Ç wtedy dok≈Çadnie to, co wiem teraz, to bym siƒô nie zdecydowa≈Ç.\n",
            "3 (score = 0.068): Gdybym wiedzia≈Ç wtedy dok≈Çadnie to, co wiem teraz, to bym siƒô nie wybra≈Ç.\n",
            "4 (score = 0.057): Gdybym wiedzia≈Ç wtedy dok≈Çadnie to, co wiem teraz, to bym siƒô nie pojawi≈Ç.\n",
            "5 (score = 0.046): Gdybym wiedzia≈Ç wtedy dok≈Çadnie to, co wiem teraz, to bym siƒô nie przygotowa≈Ç.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "use_papuga(\"Gdybym wiedzia≈Ç wtedy dok≈Çadnie to, co wiem teraz, to bym siƒô nie\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nSKhRAVcHLKn",
        "outputId": "a8ecc7ee-3f1c-438a-cb8c-5a623a91c705"
      },
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1: Gdybym wiedzia≈Ç wtedy dok≈Çadnie to, co wiem teraz, to bym siƒô nie zgodzi≈Ç. Tak jak ja jestem przekonany, ≈ºe jest to czƒô≈õƒá procesu my≈õlenia i\n",
            "2: Gdybym wiedzia≈Ç wtedy dok≈Çadnie to, co wiem teraz, to bym siƒô nie martwi≈Ç, ≈ºe przez brak wiary straci≈Çem sw√≥j udzia≈Ç w budowaniu tej ziemi\n",
            "3: Gdybym wiedzia≈Ç wtedy dok≈Çadnie to, co wiem teraz, to bym siƒô nie zastanawia≈Ç.\n",
            "Co do tego, ≈ºe co≈õ jest dobre, to ja nie\n",
            "4: Gdybym wiedzia≈Ç wtedy dok≈Çadnie to, co wiem teraz, to bym siƒô nie zgodzi≈Ç! (1) A wtedy Pan odpowiedzia≈Ç mi: Zaprawdƒô, m√≥wiƒô\n",
            "5: Gdybym wiedzia≈Ç wtedy dok≈Çadnie to, co wiem teraz, to bym siƒô nie zgodzi≈Ç, bo gdybym wiedzia≈Ç z ≈Çatwo≈õciƒÖ to, co wiem dzi≈õ, by≈Çbym g≈Çup\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Check if the model captures real-world knowledge. Define at lest 3 sentences."
      ],
      "metadata": {
        "id": "Kh_7iqh3H5EH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = [\"Bitwa pod Grunwaldem mia≈Ça miejsce w\", \"roku.\"]"
      ],
      "metadata": {
        "id": "vRmuheEFHbBW"
      },
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "use_polbert(*sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-dBfHYAkIX_X",
        "outputId": "ad9ae922-e3ba-47f7-b530-a402c2208b65"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 (score = 0.060): bitwa pod grunwaldem mia≈Ça miejsce w 1920 roku.\n",
            "2 (score = 0.037): bitwa pod grunwaldem mia≈Ça miejsce w 1919 roku.\n",
            "3 (score = 0.037): bitwa pod grunwaldem mia≈Ça miejsce w 1939 roku.\n",
            "4 (score = 0.029): bitwa pod grunwaldem mia≈Ça miejsce w 1792 roku.\n",
            "5 (score = 0.029): bitwa pod grunwaldem mia≈Ça miejsce w 1945 roku.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "use_roberta(*sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjAc0PDGIcfX",
        "outputId": "1ac7a86e-32d5-4449-b758-65a3c84b73a9"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 (score = 0.142): Bitwa pod Grunwaldem mia≈Ça miejsce w 1918 roku.\n",
            "2 (score = 0.138): Bitwa pod Grunwaldem mia≈Ça miejsce w 1945 roku.\n",
            "3 (score = 0.127): Bitwa pod Grunwaldem mia≈Ça miejsce w 1939 roku.\n",
            "4 (score = 0.081): Bitwa pod Grunwaldem mia≈Ça miejsce w 1914 roku.\n",
            "5 (score = 0.056): Bitwa pod Grunwaldem mia≈Ça miejsce w 1920 roku.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "use_papuga(sentence[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9LRdgtAIeoP",
        "outputId": "b0eaae28-063a-48b8-8c0a-15fc749b34c8"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1: Bitwa pod Grunwaldem mia≈Ça miejsce w 1421 roku, a jej pomys≈ÇodawcƒÖ by≈Ç Jan D≈Çugosz. Jednak dopiero\n",
            "2: Bitwa pod Grunwaldem mia≈Ça miejsce w latach 1410-1414. W tym czasie pa≈Ñstwo krzy≈ºackie by≈Ço ju≈º\n",
            "3: Bitwa pod Grunwaldem mia≈Ça miejsce w roku 1412, kiedy to w bitwie pod Grunwaldem wojska krzy≈ºackie straci≈Çy\n",
            "4: Bitwa pod Grunwaldem mia≈Ça miejsce w roku 1410. Kr√≥l W≈Çadys≈Çaw Jagie≈Ç≈Ço og≈Çosi≈Ç jƒÖ w 1421 roku.\n",
            "5: Bitwa pod Grunwaldem mia≈Ça miejsce w roku 1454, a wiƒôc mniej wiƒôcej w tym samym czasie, w kt√≥rym\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = [\"Najwiƒôkszym kontynentem jest\", \".\"]"
      ],
      "metadata": {
        "id": "dK8vVtK7IqoP"
      },
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "use_polbert(*sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f391207c-35b3-412a-c74b-9c56b9f85b5f",
        "id": "T_-cpjO3JCCS"
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 (score = 0.118): najwiekszym kontynentem jest australia.\n",
            "2 (score = 0.049): najwiekszym kontynentem jest afryka.\n",
            "3 (score = 0.040): najwiekszym kontynentem jest ameryka.\n",
            "4 (score = 0.030): najwiekszym kontynentem jest anglia.\n",
            "5 (score = 0.030): najwiekszym kontynentem jest brazylia.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "use_roberta(*sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c55b59db-3b8e-4e86-ac0f-20a8c74b31cf",
        "id": "hhDndk4pJCCS"
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 (score = 0.250): Najwiƒôkszym kontynentem jest Australia.\n",
            "2 (score = 0.132): Najwiƒôkszym kontynentem jest Madagaskar.\n",
            "3 (score = 0.118): Najwiƒôkszym kontynentem jest Europa.\n",
            "4 (score = 0.044): Najwiƒôkszym kontynentem jest USA.\n",
            "5 (score = 0.034): Najwiƒôkszym kontynentem jest India.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "use_papuga(sentence[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf1608c1-b230-4d15-bee5-b0ae79b322dc",
        "id": "rBiy2xIwJCCT"
      },
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1: Najwiƒôkszym kontynentem jest oczywi≈õcie Australia, a konkretnie jej p√≥≈Çnocna czƒô≈õƒá - Australia Po≈Çudniowa (po≈Çudni\n",
            "2: Najwiƒôkszym kontynentem jest Australia, a w szczeg√≥lno≈õci okolice Melbourne. Tamtejsza natura jest\n",
            "3: Najwiƒôkszym kontynentem jest Afryka ≈örodkowa na wysoko≈õci 1200-1300 m n.p.m\n",
            "4: Najwiƒôkszym kontynentem jest Azja ‚Äì tam ma sw√≥j poczƒÖtek Azjƒô, w kt√≥rej mo≈ºna zaobserwowaƒá najwiƒôkszƒÖ ilo≈õƒá\n",
            "5: Najwiƒôkszym kontynentem jest w≈Ça≈õnie Afryka.\n",
            "W tym regionie, je≈õli siƒô nie chce, mo≈ºna znale≈∫ƒá\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = [\"JednƒÖ z planet Uk≈Çadu S≈Çonecznego jest\", \".\"]"
      ],
      "metadata": {
        "id": "pZUbVA7OI3Ju"
      },
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "use_polbert(*sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7386b5ea-c885-4b14-ef71-7e3b65bd6e0f",
        "id": "1_Jr4fwxJVni"
      },
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 (score = 0.137): jedna z planet uk≈Çadu s≈Çonecznego jest ziemia.\n",
            "2 (score = 0.048): jedna z planet uk≈Çadu s≈Çonecznego jest andromeda.\n",
            "3 (score = 0.041): jedna z planet uk≈Çadu s≈Çonecznego jest planeta.\n",
            "4 (score = 0.040): jedna z planet uk≈Çadu s≈Çonecznego jest wenus.\n",
            "5 (score = 0.028): jedna z planet uk≈Çadu s≈Çonecznego jest tutaj.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "use_roberta(*sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68626ffa-5361-45e7-8984-5df009fd168a",
        "id": "aSrlKawyJVnj"
      },
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 (score = 0.362): JednƒÖ z planet Uk≈Çadu S≈Çonecznego jest Saturn.\n",
            "2 (score = 0.309): JednƒÖ z planet Uk≈Çadu S≈Çonecznego jest Mars.\n",
            "3 (score = 0.085): JednƒÖ z planet Uk≈Çadu S≈Çonecznego jest Jupiter.\n",
            "4 (score = 0.078): JednƒÖ z planet Uk≈Çadu S≈Çonecznego jest Neptun.\n",
            "5 (score = 0.027): JednƒÖ z planet Uk≈Çadu S≈Çonecznego jest Luna.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "use_papuga(sentence[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "841a997a-fc4e-4e9d-b17b-f40f87f254a7",
        "id": "wFN3pqA9JVnj"
      },
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1: JednƒÖ z planet Uk≈Çadu S≈Çonecznego jest Wenus, zwana tak≈ºe w skr√≥cie Wenus, po≈Ço≈ºona na granicy miƒôdzy Zie\n",
            "2: JednƒÖ z planet Uk≈Çadu S≈Çonecznego jest Ksiƒô≈ºyc, kt√≥ry jest obecnie najbardziej oddalonym od Ziemi cia≈Çem niebieskim, a w\n",
            "3: JednƒÖ z planet Uk≈Çadu S≈Çonecznego jest Wenus, kt√≥ra jest uwa≈ºana za najbardziej znanƒÖ planetƒô Uk≈Çadu S≈Çonecznego\n",
            "4: JednƒÖ z planet Uk≈Çadu S≈Çonecznego jest kometa (Gaia), a dok≈Çadniej ich najbli≈ºsza rodzina komet.\n",
            "5: JednƒÖ z planet Uk≈Çadu S≈Çonecznego jest planeta ‚Äì S≈Ço≈Ñce. Jej nazwa nawiƒÖzuje do nazwy planety oraz jej koloru.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Answer the following questions:\n",
        "\n",
        "### a. Which of the models produced the best results?\n",
        "\n",
        "In my opinion the best results were produces by Polish BERT. Most of its guesses were matching the context and grammar.\n",
        "\n",
        "### b. Was any of the models able to capture Polish grammar?\n",
        "\n",
        "Papuga was generating sentences with mostly correct grammar. Polbert was excellent in polish cases, while Robert did some mistakes.\n",
        "\n",
        "### c. Was any of the models able to capture long-distant relationships between the words?\n",
        "\n",
        "Every model did a good job in capturing long-distance relationships beetwen the words (such as gender).\n",
        "\n",
        "### d. Was any of the models able to capture world knowledge?\n",
        "\n",
        "None of the models has a very accurate world knowledge, such as what is the biggest continent (although most guesses were continents) or in which year did the Grunwald battle take place (apart from Papuga in some guesses). But when it came to naming planets, the guesses where much closer.\n",
        "\n",
        "### e. What are the most striking errors made by the models?\n",
        "\n",
        "The most striking errors are when the model did not understand the context, and, although the form of the word is correct, it doesn't fit in the sentence. For example `S≈Ço≈Ñ to najwiƒôksze ≈∫r√≥d≈Ço na ≈õwiecie.`, `Ta dziewczyna z d≈Çugimi czasami by≈Ça bardzo ≈Çadna.`. Most of such mistakes were made by the RoBERT model, which is the biggest of all three. This might be because it was trained on 94 languages while the remaining two only on Polish language."
      ],
      "metadata": {
        "id": "VJinCvQvJ-fo"
      }
    }
  ]
}