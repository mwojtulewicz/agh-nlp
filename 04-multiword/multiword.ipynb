{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiword expression identification and extraction\n",
    "Mateusz Wojtulewicz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import tqdm\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Use SpaCy tokenizer API to tokenize the text from the law corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"pl_core_news_sm\")\n",
    "tokenizer = nlp.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenizing acts: 100%|██████████| 1179/1179 [00:37<00:00, 31.82it/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_acts = {}\n",
    "\n",
    "acts_dir = Path(\"../data/ustawy/\")\n",
    "n_acts = len(list(acts_dir.iterdir()))\n",
    "\n",
    "for act in tqdm.tqdm(acts_dir.iterdir(), desc=\"Tokenizing acts\", total=n_acts):\n",
    "    act_id = act.stem\n",
    "    content = act.read_text(encoding=\"utf8\")\n",
    "    tokens = tokenizer(content)\n",
    "    tokenized_acts[act_id] = [token.text.lower() for token in tokens]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Compute bigram counts of downcased tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams = (\n",
    "    (f, s)\n",
    "    for tokens in tokenized_acts.values()\n",
    "    for (f, s) in zip(tokens[:-1], tokens[1:])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams_count = Counter(bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('art', '.'), 83778),\n",
       " (('ust', '.'), 53552),\n",
       " (('.', '\\n'), 49741),\n",
       " (('poz', '.'), 45198),\n",
       " ((',', 'poz'), 39655),\n",
       " (('-', '-'), 36542),\n",
       " (('r', '.'), 33015),\n",
       " (('w', 'art'), 30170),\n",
       " (('.', '1'), 29734),\n",
       " ((',', 'o'), 28739)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams_count.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Discard bigrams containing characters other than letters. Make sure that you discard the invalid entries after computing the bigram counts.\n",
    "\n",
    "I'm using a Token's property `is_alpha` which is `True` if the token consists only of alphabetic characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_word(s: str) -> bool:\n",
    "   return tokenizer(s)[0].is_alpha "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams_filtered = (\n",
    "    (f, s)\n",
    "    for tokens in tokenized_acts.values()\n",
    "    for (f, s) in zip(tokens[:-1], tokens[1:])\n",
    "    if is_word(f) and is_word(s)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams_filtered_count = Counter(bigrams_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('w', 'art'), 30170),\n",
       " (('mowa', 'w'), 27649),\n",
       " (('w', 'ust'), 22238),\n",
       " (('których', 'mowa'), 12973),\n",
       " (('o', 'których'), 12604),\n",
       " (('otrzymuje', 'brzmienie'), 9168),\n",
       " (('z', 'dnia'), 8989),\n",
       " (('którym', 'mowa'), 8689),\n",
       " (('o', 'którym'), 8525),\n",
       " (('do', 'spraw'), 8215),\n",
       " (('dodaje', 'się'), 7960),\n",
       " (('i', 'nr'), 7871),\n",
       " (('w', 'brzmieniu'), 6690),\n",
       " (('w', 'drodze'), 6623),\n",
       " (('stosuje', 'się'), 6232),\n",
       " (('na', 'podstawie'), 5906),\n",
       " (('w', 'przypadku'), 5371),\n",
       " (('której', 'mowa'), 5192),\n",
       " (('o', 'której'), 5061),\n",
       " (('od', 'dnia'), 4971)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams_filtered_count.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Use pointwise mutual information to compute the measure for all pairs of words.\n",
    "The _PMI_ of a pair of outcomes $x$ and $y$ is calculated as follows:\n",
    "$$\n",
    "\\text{pmi}(x; y) = \\log_2 \\frac{p(x, y)}{p(x)p(y)}\n",
    "$$\n",
    "\n",
    "In our case:\n",
    "- $p(x, y)$ is a probability of drawing a bigram $(x,y)$ from all bigrams in the corpus;\n",
    "- $p(x)$ is a probabilty of drawing a token $x$ from all tokens in the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_count = Counter(\n",
    "    token for tokens in tokenized_acts.values() for token in tokens\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('.', 437694),\n",
       " (',', 341126),\n",
       " ('w', 201224),\n",
       " ('\\n', 181703),\n",
       " (')', 100194),\n",
       " ('i', 90009),\n",
       " ('art', 83804),\n",
       " ('z', 82443),\n",
       " ('1', 73108),\n",
       " ('o', 64776)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_count.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving counters to be used to calculate _PMI_ in a `pmi_bigram_mp.py` script that uses parallelization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def dump_counter(counter: Counter, name: str) -> None:\n",
    "    with open(f\"{name}.p\", \"wb\") as f:\n",
    "        pickle.dump(counter, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_counter(bigrams_count, \"bigrams_counter\")\n",
    "dump_counter(bigrams_filtered_count, \"bigrams_filtered_counter\")\n",
    "dump_counter(tokens_count, \"tokens_counter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading calculated results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams_pmi = pickle.load(open(\"pmi_results.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Sort the word pairs according to that measure in the descending order and determine top 10 entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('kołowe', 'jednoosiowe'), 22.475522182157892),\n",
       " (('zbrojeń', 'żelbeto'), 22.475522182157892),\n",
       " (('prefabrykatów', 'wnętrzowe'), 22.475522182157892),\n",
       " (('gołe', 'aluminiowe'), 22.475522182157892),\n",
       " (('polistyrenu', 'spienionego'), 22.475522182157892),\n",
       " (('objaśnieniem', 'figur'), 22.475522182157892),\n",
       " (('wkładzie', 'wnoszonym'), 22.475522182157892),\n",
       " (('doktorem', 'habilitowanym'), 22.475522182157892),\n",
       " (('losy', 'loteryjne'), 22.475522182157892),\n",
       " (('ugaszone', 'zapałki'), 22.475522182157892)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(bigrams_pmi, key=lambda x: -x[1])[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Filter bigrams with number of occurrences lower than 5. Determine top 10 entries for the remaining dataset (>=5 occurrences)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('diagności', 'laboratoryjni'), 19.890559681436738),\n",
       " (('odczynów', 'poszczepiennych'), 19.890559681436738),\n",
       " (('adama', 'mickiewicza'), 19.890559681436738),\n",
       " (('papierem', 'wartościowym'), 19.66816726010029),\n",
       " (('piotrków', 'trybunalski'), 19.66816726010029),\n",
       " (('lambrekiny', 'okienne'), 19.66816726010029),\n",
       " (('schedę', 'spadkową'), 19.66816726010029),\n",
       " (('buraka', 'cukrowego'), 19.475522182157892),\n",
       " (('zdrowego', 'stylu'), 19.475522182157892),\n",
       " (('zapieczętowanej', 'kopercie'), 19.445774838763842)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams_pmi_5 = [(bigram, pmi) for bigram, pmi in bigrams_pmi if bigrams_count[bigram] > 5]\n",
    "sorted(bigrams_pmi_5, key=lambda x: -x[1])[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Use KRNNT or Clarin-PL API to tag and lemmatize the corpus.\n",
    "\n",
    "I've used Clarin-PL API with Moreusz 1, and then I've downloaded the XML output files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenizing tagged acts: 100%|██████████| 1179/1179 [02:16<00:00,  8.63it/s]\n"
     ]
    }
   ],
   "source": [
    "tag_tokenized_acts = {}\n",
    "\n",
    "tag_acts_dir = Path(\"../data/ustawy_tagged_clarin_morf1/\")\n",
    "n_acts = len(list(tag_acts_dir.iterdir()))\n",
    "\n",
    "for act in tqdm.tqdm(tag_acts_dir.iterdir(), desc=\"Tokenizing tagged acts\", total=n_acts):\n",
    "    act_id = act.stem\n",
    "    content = act.read_text(encoding=\"utf8\")\n",
    "    tree = ET.fromstring(text=content)\n",
    "    tag_tokens = []\n",
    "    for tok in tree.iter(\"tok\"):\n",
    "        lex = tok.find(\"lex\")\n",
    "        base = lex.find(\"base\").text\n",
    "        ctag = lex.find(\"ctag\").text\n",
    "        tag_token = f\"{base.lower()}:{ctag.split(':')[0]}\"\n",
    "        tag_tokens.append(tag_token)\n",
    "    tag_tokenized_acts[act_id] = tag_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Using the tagged corpus compute bigram statistic for the tokens containing: a. lemmatized, downcased word b. morphosyntactic category of the word (subst, fin, adj, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_bigrams = [\n",
    "    (f, s)\n",
    "    for tag_tokens in tag_tokenized_acts.values()\n",
    "    for (f, s) in zip(tag_tokens[:-1], tag_tokens[1:])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_bigrams_counter = Counter(tag_bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('art:brev', '.:interp'), 83700),\n",
       " (('usta:subst', '.:interp'), 53553),\n",
       " (('poz:brev', '.:interp'), 45195),\n",
       " ((',:interp', 'poz:brev'), 43166),\n",
       " (('.:interp', '1:adj'), 39987),\n",
       " (('-:interp', '-:interp'), 36548),\n",
       " (('r:brev', '.:interp'), 33029),\n",
       " (('w:prep', 'art:brev'), 31988),\n",
       " ((',:interp', 'o:prep'), 29906),\n",
       " (('o:prep', 'który:adj'), 28646)]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_bigrams_counter.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I am filtering tokens that base is a word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_word_base(token: str) -> bool:\n",
    "    parts = token.split(\":\")\n",
    "    if len(parts) != 2:\n",
    "        return False\n",
    "    else:\n",
    "        return is_word(s=parts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_bigrams_filtered = (\n",
    "    (f, s)\n",
    "    for tag_tokens in tag_tokenized_acts.values()\n",
    "    for (f, s) in zip(tag_tokens[:-1], tag_tokens[1:])\n",
    "    if is_word_base(f) and is_word_base(s)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_bigrams_filtered_counter = Counter(tag_bigrams_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('w:prep', 'art:brev'), 31988),\n",
       " (('o:prep', 'który:adj'), 28646),\n",
       " (('który:adj', 'mowa:subst'), 28538),\n",
       " (('mowa:subst', 'w:prep'), 28473),\n",
       " (('w:prep', 'usta:subst'), 23557),\n",
       " (('z:prep', 'dzień:subst'), 11360),\n",
       " (('otrzymywać:fin', 'brzmienie:subst'), 10536),\n",
       " (('określić:ppas', 'w:prep'), 10169),\n",
       " (('do:prep', 'sprawa:subst'), 8716),\n",
       " (('ustawa:subst', 'z:prep'), 8625),\n",
       " (('właściwy:adj', 'do:prep'), 8535),\n",
       " (('i:conj', 'nr:brev'), 8435),\n",
       " (('dodawać:fin', 'się:qub'), 8195),\n",
       " (('minister:subst', 'właściwy:adj'), 7931),\n",
       " (('w:prep', 'brzmienie:subst'), 7280),\n",
       " (('w:prep', 'droga:subst'), 7128),\n",
       " (('w:prep', 'przypadek:subst'), 6776),\n",
       " (('na:prep', 'podstawa:subst'), 6681),\n",
       " (('stosować:fin', 'się:qub'), 6535),\n",
       " (('się:qub', 'wyraz:subst'), 6077)]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_bigrams_filtered_counter.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Compute the same statistics as for the non-lemmatized words (i.e. PMI) and print top-10 entries with at least 5 occurrences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_tokens_counter = Counter(\n",
    "    tag_token for tag_tokens in tag_tokenized_acts.values() for tag_token in tag_tokens\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('.:interp', 457356),\n",
       " (',:interp', 343058),\n",
       " ('w:prep', 202567),\n",
       " ('):interp', 102195),\n",
       " ('z:prep', 87991),\n",
       " ('i:conj', 87725),\n",
       " ('art:brev', 83706),\n",
       " ('1:adj', 74500),\n",
       " ('o:prep', 64712),\n",
       " ('-:interp', 61833)]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_tokens_counter.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving counters to be used to calculate _PMI_ in a `pmi_bigram_mp.py` script that uses parallelization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_counter(tag_bigrams_counter, \"tag_bigrams_counter\")\n",
    "dump_counter(tag_bigrams_filtered_counter, \"tag_bigrams_filtered_counter\")\n",
    "dump_counter(tag_tokens_counter, \"tag_tokens_counter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading calculated results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_bigrams_pmi = pickle.load(open(\"tag_pmi_results.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top 10 bigrams with any number of occurrences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('tornister:subst', 'nieskórzany:adj'), 22.330150430961186),\n",
       " (('zbrojenia:subst', 'żelbeto:adja'), 22.330150430961186),\n",
       " (('reduktor:subst', 'membranowy:adj'), 22.330150430961186),\n",
       " (('prefabrykat:subst', 'wnętrzowy:adj'), 22.330150430961186),\n",
       " (('polistyren:subst', 'spienić:ppas'), 22.330150430961186),\n",
       " (('uw:subst', 'zględnieniu:subst'), 22.330150430961186),\n",
       " (('english:subst', 'language:subst'), 22.330150430961186),\n",
       " (('language:subst', 'college:subst'), 22.330150430961186),\n",
       " (('southern:subst', 'trade:subst'), 22.330150430961186),\n",
       " (('łęka:subst', 'dukielski:adj'), 22.330150430961186)]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(tag_bigrams_pmi, key=lambda x: -x[1])[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top 10 bigrams with at least 5 occurrences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('adam:subst', 'mickiewicz:subst'), 19.74518793024003),\n",
       " (('piotrków:subst', 'trybunalski:adj'), 19.52279550890358),\n",
       " (('przeponowy:adj', 'rurowy:adj'), 19.330150430961186),\n",
       " (('chrześcijanin:subst', 'baptysta:subst'), 19.10775800962474),\n",
       " (('maria:subst', 'curie:subst'), 19.00822233607382),\n",
       " (('hugo:subst', 'kołłątaj:subst'), 19.00822233607382),\n",
       " (('tadeusz:subst', 'kotarbiński:subst'), 19.00822233607382),\n",
       " (('upośledzony:adj', 'umysłowo:adv'), 18.870718812323886),\n",
       " (('jedwab:subst', 'wiskozowy:adj'), 18.870718812323886),\n",
       " (('vitis:subst', 'vinifera:subst'), 18.870718812323886)]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_bigrams_pmi_5 = [(tag_bigram, pmi) for tag_bigram, pmi in tag_bigrams_pmi if tag_bigrams_counter[tag_bigram] > 5]\n",
    "sorted(tag_bigrams_pmi_5, key=lambda x: -x[1])[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Compute **trigram** counts for both corpora and perform the same filtering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Non-lemmatized corpora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigrams_counter = Counter(\n",
    "    (first, second, third)\n",
    "    for tokens in tokenized_acts.values()\n",
    "    for (first, second, third) in zip(tokens, tokens[1:], tokens[2:])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((',', 'poz', '.'), 39633),\n",
       " (('-', '-', '-'), 34641),\n",
       " (('w', 'art', '.'), 30162),\n",
       " (('ust', '.', '1'), 22618),\n",
       " (('w', 'ust', '.'), 22204),\n",
       " (('r', '.', 'nr'), 16956),\n",
       " (('_', '_', '_'), 16111),\n",
       " (('których', 'mowa', 'w'), 12506),\n",
       " (('mowa', 'w', 'ust'), 12388),\n",
       " ((',', 'o', 'których'), 12009)]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigrams_counter.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigrams_filtered_counter = Counter(\n",
    "    (first, second, third)\n",
    "    for tokens in tokenized_acts.values()\n",
    "    for (first, second, third) in zip(tokens, tokens[1:], tokens[2:])\n",
    "    if is_word(first) and is_word(second) and is_word(third)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('których', 'mowa', 'w'), 12506),\n",
       " (('mowa', 'w', 'ust'), 12388),\n",
       " (('o', 'których', 'mowa'), 11714),\n",
       " (('mowa', 'w', 'art'), 10995),\n",
       " (('którym', 'mowa', 'w'), 8429),\n",
       " (('o', 'którym', 'mowa'), 8040),\n",
       " (('której', 'mowa', 'w'), 5020),\n",
       " (('o', 'której', 'mowa'), 4731),\n",
       " (('właściwy', 'do', 'spraw'), 4434),\n",
       " (('minister', 'właściwy', 'do'), 4106)]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigrams_filtered_counter.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Lemmatized and tagged corpora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_trigrams_counter = Counter(\n",
    "    (first, second, third)\n",
    "    for tokens in tag_tokenized_acts.values()\n",
    "    for (first, second, third) in zip(tokens, tokens[1:], tokens[2:])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((',:interp', 'poz:brev', '.:interp'), 43165),\n",
       " (('-:interp', '-:interp', '-:interp'), 34646),\n",
       " (('w:prep', 'art:brev', '.:interp'), 31987),\n",
       " (('o:prep', 'który:adj', 'mowa:subst'), 28525),\n",
       " ((',:interp', 'o:prep', 'który:adj'), 28445),\n",
       " (('który:adj', 'mowa:subst', 'w:prep'), 28442),\n",
       " (('w:prep', 'usta:subst', '.:interp'), 23520),\n",
       " (('usta:subst', '.:interp', '1:adj'), 23346),\n",
       " (('.:interp', 'art:brev', '.:interp'), 22917),\n",
       " (('r:brev', '.:interp', 'nr:brev'), 17860)]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_trigrams_counter.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_trigrams_filtered_counter = Counter(\n",
    "    (first, second, third)\n",
    "    for tokens in tag_tokenized_acts.values()\n",
    "    for (first, second, third) in zip(tokens, tokens[1:], tokens[2:])\n",
    "    if is_word(first) and is_word(second) and is_word(third)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('o:prep', 'który:adj', 'mowa:subst'), 28525),\n",
       " (('który:adj', 'mowa:subst', 'w:prep'), 28442),\n",
       " (('mowa:subst', 'w:prep', 'usta:subst'), 13474),\n",
       " (('mowa:subst', 'w:prep', 'art:brev'), 12293),\n",
       " (('ustawa:subst', 'z:prep', 'dzień:subst'), 8589),\n",
       " (('właściwy:adj', 'do:prep', 'sprawa:subst'), 7964),\n",
       " (('minister:subst', 'właściwy:adj', 'do:prep'), 7886),\n",
       " (('w:prep', 'droga:subst', 'rozporządzenie:subst'), 4748),\n",
       " (('zastępować:fin', 'się:qub', 'wyraz:subst'), 3653),\n",
       " (('w:prep', 'ustawa:subst', 'z:prep'), 3646)]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_trigrams_filtered_counter.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Use PMI (with 5 occurrence threshold) to compute top 10 results for the trigrams. Devise a method for computing the values, based on the results for bigrams."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am constructing _PMI_ of three outcomes $x$, $y$, $z$ to be:\n",
    "$$\n",
    "\\text{pmi}(x; y; z) = \\log_2 \\frac{p(x, y, z)}{p(x)p(y)p(z)}\n",
    "$$\n",
    "For this constructions still holds that _PMI_ of outcomes measures the divergence between probability of their coincidence and the probability of their individual, independent occurences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving counters to be used to calculate _PMI_ in a `pmi_trigram_mp.py` script that uses parallelization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_counter(trigrams_counter, \"trigrams_counter\")\n",
    "dump_counter(trigrams_filtered_counter, \"trigrams_filtered_counter\")\n",
    "\n",
    "dump_counter(tag_trigrams_counter, \"tag_trigrams_counter\")\n",
    "dump_counter(tag_trigrams_filtered_counter, \"tag_trigrams_filtered_counter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading calculated results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('ds')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2886749ed11b87e200011d0e8b34479c2c945318db21e04a15735afb52256eb9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
