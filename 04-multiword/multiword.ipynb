{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiword expression identification and extraction\n",
    "Mateusz Wojtulewicz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import tqdm\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"pl_core_news_sm\")\n",
    "tokenizer = nlp.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenizing acts: 100%|██████████| 1179/1179 [00:29<00:00, 40.24it/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_acts = {}\n",
    "\n",
    "acts_dir = Path(\"../data/ustawy/\")\n",
    "n_acts = len(list(acts_dir.iterdir()))\n",
    "\n",
    "for act in tqdm.tqdm(acts_dir.iterdir(), desc=\"Tokenizing acts\", total=n_acts):\n",
    "    act_id = act.stem\n",
    "    content = act.read_text(encoding=\"utf8\")\n",
    "    tokens = tokenizer(content)\n",
    "    tokenized_acts[act_id] = [token.text.lower() for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['\\n\\n\\n\\n', 'dz', '.'], ['dz', '.', 'u'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_acts[\"1993_599\"][:3], tokenized_acts[\"1993_599\"][1:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams = (\n",
    "    (f, s)\n",
    "    for tokens in tokenized_acts.values()\n",
    "    for (f, s) in zip(tokens[:-1], tokens[1:])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams_count = Counter(bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('art', '.'), 83778),\n",
       " (('ust', '.'), 53552),\n",
       " (('.', '\\n'), 49741),\n",
       " (('poz', '.'), 45198),\n",
       " ((',', 'poz'), 39655),\n",
       " (('-', '-'), 36542),\n",
       " (('r', '.'), 33015),\n",
       " (('w', 'art'), 30170),\n",
       " (('.', '1'), 29734),\n",
       " ((',', 'o'), 28739)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams_count.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_word(s: str) -> bool:\n",
    "   return tokenizer(s)[0].is_alpha "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams_filtered = (\n",
    "    (f, s)\n",
    "    for tokens in tokenized_acts.values()\n",
    "    for (f, s) in zip(tokens[:-1], tokens[1:])\n",
    "    if is_word(f) and is_word(s)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams_filtered_count = Counter(bigrams_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('w', 'art'), 30170),\n",
       " (('mowa', 'w'), 27649),\n",
       " (('w', 'ust'), 22238),\n",
       " (('których', 'mowa'), 12973),\n",
       " (('o', 'których'), 12604),\n",
       " (('otrzymuje', 'brzmienie'), 9168),\n",
       " (('z', 'dnia'), 8989),\n",
       " (('którym', 'mowa'), 8689),\n",
       " (('o', 'którym'), 8525),\n",
       " (('do', 'spraw'), 8215),\n",
       " (('dodaje', 'się'), 7960),\n",
       " (('i', 'nr'), 7871),\n",
       " (('w', 'brzmieniu'), 6690),\n",
       " (('w', 'drodze'), 6623),\n",
       " (('stosuje', 'się'), 6232),\n",
       " (('na', 'podstawie'), 5906),\n",
       " (('w', 'przypadku'), 5371),\n",
       " (('której', 'mowa'), 5192),\n",
       " (('o', 'której'), 5061),\n",
       " (('od', 'dnia'), 4971)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams_filtered_count.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_count = Counter(\n",
    "    token for tokens in tokenized_acts.values() for token in tokens\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('.', 437694),\n",
       " (',', 341126),\n",
       " ('w', 201224),\n",
       " ('\\n', 181703),\n",
       " (')', 100194),\n",
       " ('i', 90009),\n",
       " ('art', 83804),\n",
       " ('z', 82443),\n",
       " ('1', 73108),\n",
       " ('o', 64776)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_count.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\text{pmi}(x; y) \\equiv  \\log_2 \\frac{p(x, y)}{p(x)p(y)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_bigram(bigram: tuple[str, str]) -> float:\n",
    "    tok1, tok2 = bigram\n",
    "    N = sum(bigrams_count.values())\n",
    "    return bigrams_filtered_count[(tok1, tok2)] / N\n",
    "\n",
    "def p_token(tok: str) -> float:\n",
    "    N = sum(bigrams_count.values())\n",
    "    return tokens_count[tok] / N\n",
    "\n",
    "def pmi_bigram(bigram: tuple[str, str]) -> float:\n",
    "    tok1, tok2 = bigram\n",
    "    return np.log2(p_bigram(bigram) / (p_token(tok1) * p_token(tok2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def dump_counter(counter: Counter, name: str) -> None:\n",
    "    with open(f\"{name}.p\", \"wb\") as f:\n",
    "        pickle.dump(counter, f)\n",
    "        \n",
    "def load_counter(name) -> Counter:\n",
    "    with open(f\"{name}.p\", \"rb\") as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_counter(bigrams_count, \"bigrams_counter\")\n",
    "dump_counter(bigrams_filtered_count, \"bigrams_filtered_counter\")\n",
    "dump_counter(tokens_count, \"tokens_counter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams_pmi = [\n",
    "    (bigram, pmi_bigram(bigram))\n",
    "    for bigram in bigrams_filtered_count.keys()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('dotychczasowa', 'treść'), 13.116306854406337),\n",
       " (('podatku', 'akcyzowym'), 10.68410880396931),\n",
       " (('zmianie', 'ustawy'), 7.925625340522062),\n",
       " (('wprowadza', 'się'), 6.791221905648496),\n",
       " (('się', 'następujące'), 6.513427944429425),\n",
       " (('o', 'zmianie'), 6.124066689390784),\n",
       " (('podatku', 'od'), 5.948931080356767),\n",
       " (('ustawie', 'z'), 5.548346488207807),\n",
       " (('od', 'towarów'), 5.502196529733125),\n",
       " (('treść', 'otrzymuje'), 5.496453707015169),\n",
       " (('z', 'dnia'), 5.146340032871757),\n",
       " (('w', 'ustawie'), 4.6595349327468325),\n",
       " (('o', 'podatku'), 4.4465467303567605),\n",
       " (('i', 'usług'), 4.3923637697079725),\n",
       " (('towarów', 'i'), 4.088129866766435),\n",
       " (('usług', 'oraz'), 3.666199941233582),\n",
       " (('i', 'nr'), 3.50403826809644),\n",
       " (('w', 'art'), 3.3831749124593045),\n",
       " (('ustawy', 'o'), 3.2601962081221934),\n",
       " (('oraz', 'o'), 1.279755286233716)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(bigrams_pmi.items(), key=lambda x: -x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: multiprocessing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('ds')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2886749ed11b87e200011d0e8b34479c2c945318db21e04a15735afb52256eb9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
